{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476b9adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìÅ ANALYZING: prompt_0_base\n",
      "üìù Prompt: adapt logo for holiday t-shirt print with seasonal elements...\n",
      "üé® Scenario: tshirt design\n",
      "======================================================================\n",
      "\n",
      "üì∏ Found 5 images to analyze\n",
      "\n",
      "ü§ñ claude_3_opus        \n",
      "      üìé Encoded image: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/input_image.png (64296 chars)\n",
      "\n",
      "      üìé Encoded image: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/final_output.png (160708 chars)\n",
      "\n",
      "      üìé Encoded image: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/word_attribution_complete.png (276852 chars)\n",
      "\n",
      "      üìé Encoded image: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/evolution_grid.png (317276 chars)\n",
      "\n",
      "      üìé Encoded image: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/timestep_evolution_seasonal.png (145936 chars)\n",
      "\n",
      "      üì§ Payload size: 967118 bytes\n",
      "      üì§ Content blocks: 6 (5 images, 1 text)\n",
      "      üì§ Temperature: included\n",
      "\n",
      "      üìä Status: 200\n",
      "      üìä Response size: 2120 bytes\n",
      "      üìä Response keys: ['content', 'usage', 'metadata']\n",
      "‚úÖ Done (22.9s, 1594 chars)\n",
      "ü§ñ claude_3_sonnet      ‚úÖ Done (13.1s, 1644 chars)\n",
      "ü§ñ claude_3_haiku       ‚úÖ Done (6.5s, 1707 chars)\n",
      "ü§ñ claude_3.5_sonnet    ‚úÖ Done (11.1s, 1684 chars)\n",
      "ü§ñ claude_3.5_haiku     ‚ùå Failed (1.2s)\n",
      "ü§ñ claude_4_opus        ‚ùå Failed (29.3s)\n",
      "ü§ñ claude_4_sonnet      ‚úÖ Done (13.0s, 1883 chars)\n",
      "ü§ñ claude_4.5_sonnet    ‚úÖ Done (17.7s, 2838 chars)\n",
      "ü§ñ claude_4.5_haiku     ‚úÖ Done (8.7s, 2694 chars)\n",
      "üìÑ Summary saved: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/llm_analysis/ANALYSIS_SUMMARY.md\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETE! Analyzed with 9 LLMs\n",
      "üìä Results saved to: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/llm_analysis\n",
      "üìÑ Report: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/llm_analysis/ANALYSIS_SUMMARY.md\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nanalyze_multiple_prompts([\\n    \"flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base\",\\n    \"flux_experiments/run_20251116_013857/tshirt_design/prompt_2_variant2\",\\n    \"flux_experiments/run_20251116_013857/mug_design/prompt_1_variant1\"\\n])\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Single-Prompt LLM Analysis\n",
    "Analyzes one specific prompt folder with multiple LLMs (fast & parallel-friendly)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# ===== AWS BEDROCK CONFIGURATION =====\n",
    "API_ENDPOINT = \"https://ctwa92wg1b.execute-api.us-east-1.amazonaws.com/prod/invoke\"\n",
    "TEAM_ID = \"team_the_great_hack_2025_022\"\n",
    "API_TOKEN = \"znqXT5zCmCynAx-kyx_hldrxvSeyaWvxzx55vB5mfNg\"\n",
    "\n",
    "# ===== EXPANDED LLM SELECTION (All Claude models) =====\n",
    "LLMS_TO_TEST = {\n",
    "    # Claude 3 Series\n",
    "    \"claude_3_opus\": \"us.anthropic.claude-3-opus-20240229-v1:0\",  # Most Powerful (3.x)\n",
    "    \"claude_3_sonnet\": \"us.anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"claude_3_haiku\": \"us.anthropic.claude-3-haiku-20240307-v1:0\",  # Fastest (3.x)\n",
    "    \n",
    "    # Claude 3.5 Series\n",
    "    \"claude_3.5_sonnet\": \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",  # Recommended\n",
    "    \"claude_3.5_haiku\": \"us.anthropic.claude-3-5-haiku-20241022-v1:0\",  # Fast\n",
    "    \n",
    "    # Claude 4 Series (Latest)\n",
    "    \"claude_4_opus\": \"us.anthropic.claude-opus-4-20250514-v1:0\",\n",
    "    \"claude_4_sonnet\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "    \"claude_4.5_sonnet\": \"us.anthropic.claude-sonnet-4-5-20250929-v1:0\",  # Latest & Smartest\n",
    "    \"claude_4.5_haiku\": \"us.anthropic.claude-haiku-4-5-20251001-v1:0\",\n",
    "}\n",
    "\n",
    "# Model-specific configurations\n",
    "MODEL_CONFIGS = {\n",
    "    # All Claude models support temperature and vision\n",
    "    \"no_temperature\": [],\n",
    "    \"small_context\": [],\n",
    "    \"limited_vision\": []\n",
    "}\n",
    "\n",
    "# ===== HELPER FUNCTIONS =====\n",
    "def resize_image_if_needed(image_path, max_dimension=1568, quality=85):\n",
    "    \"\"\"\n",
    "    Resize image to fit within API limits while maintaining quality\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image file\n",
    "        max_dimension: Max width or height (Claude supports up to 1568px)\n",
    "        quality: JPEG quality (85 is good balance)\n",
    "    \n",
    "    Returns:\n",
    "        Base64 encoded image string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            # Convert to RGB if necessary (handles RGBA, grayscale, etc.)\n",
    "            if img.mode not in ('RGB', 'L'):\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Get original dimensions\n",
    "            width, height = img.size\n",
    "            \n",
    "            # Calculate if resize is needed\n",
    "            if max(width, height) > max_dimension:\n",
    "                # Calculate new dimensions maintaining aspect ratio\n",
    "                if width > height:\n",
    "                    new_width = max_dimension\n",
    "                    new_height = int(height * (max_dimension / width))\n",
    "                else:\n",
    "                    new_height = max_dimension\n",
    "                    new_width = int(width * (max_dimension / height))\n",
    "                \n",
    "                # Resize with high-quality resampling\n",
    "                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Save to bytes buffer as JPEG (much smaller than PNG)\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format='JPEG', quality=quality, optimize=True)\n",
    "            buffer.seek(0)\n",
    "            \n",
    "            # Encode to base64\n",
    "            img_b64 = base64.b64encode(buffer.read()).decode('utf-8')\n",
    "            \n",
    "            return img_b64, 'image/jpeg'\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to process image {image_path}: {str(e)}\")\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Convert image to base64 for API (legacy, use resize_image_if_needed instead)\"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def call_bedrock_llm(model_id, prompt, images=None, debug=False):\n",
    "    \"\"\"Call AWS Bedrock via API\"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-api-key\": API_TOKEN\n",
    "    }\n",
    "    \n",
    "    content = []\n",
    "    \n",
    "    # Determine image size based on model capabilities\n",
    "    if model_id in MODEL_CONFIGS[\"small_context\"]:\n",
    "        max_dim = 800  # Smaller images for limited context models\n",
    "        quality = 70\n",
    "    else:\n",
    "        max_dim = 1200  # Standard size\n",
    "        quality = 80\n",
    "    \n",
    "    # Check if model has limited vision support\n",
    "    if model_id in MODEL_CONFIGS[\"limited_vision\"]:\n",
    "        if debug:\n",
    "            print(f\"\\n      ‚ö†Ô∏è  Model has limited vision support, using only first 2 images\")\n",
    "        images = images[:2] if images else []  # Only use first 2 images\n",
    "    \n",
    "    if images:\n",
    "        for img_path in images:\n",
    "            try:\n",
    "                # Use optimized image encoding\n",
    "                img_b64, media_type = resize_image_if_needed(img_path, max_dimension=max_dim, quality=quality)\n",
    "                \n",
    "                if debug:\n",
    "                    print(f\"\\n      üìé Encoded image: {img_path} ({len(img_b64)} chars)\")\n",
    "                \n",
    "                content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": media_type,\n",
    "                        \"data\": img_b64\n",
    "                    }\n",
    "                })\n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    print(f\"\\n      ‚ö†Ô∏è  Failed to encode {img_path}: {e}\")\n",
    "                return f\"ERROR: Image encoding failed for {img_path}: {str(e)}\"\n",
    "    \n",
    "    content.append({\"type\": \"text\", \"text\": prompt})\n",
    "    \n",
    "    # Build payload with model-specific parameters\n",
    "    payload = {\n",
    "        \"team_id\": TEAM_ID,\n",
    "        \"api_token\": API_TOKEN,\n",
    "        \"model\": model_id,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": content}],\n",
    "        \"max_tokens\": 2000,\n",
    "    }\n",
    "    \n",
    "    # Only add temperature if model supports it\n",
    "    if model_id not in MODEL_CONFIGS[\"no_temperature\"]:\n",
    "        payload[\"temperature\"] = 0.3\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\n      üì§ Payload size: {len(json.dumps(payload))} bytes\")\n",
    "        print(f\"      üì§ Content blocks: {len(content)} ({len([c for c in content if c['type']=='image'])} images, {len([c for c in content if c['type']=='text'])} text)\")\n",
    "        print(f\"      üì§ Temperature: {'included' if 'temperature' in payload else 'excluded (not supported)'}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_ENDPOINT, headers=headers, json=payload, timeout=90)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\n      üìä Status: {response.status_code}\")\n",
    "            print(f\"      üìä Response size: {len(response.text)} bytes\")\n",
    "        \n",
    "        # Check status before parsing JSON\n",
    "        if response.status_code != 200:\n",
    "            error_text = response.text[:500]\n",
    "            if debug:\n",
    "                print(f\"\\n      ‚ùå Error response: {error_text}\")\n",
    "            return f\"ERROR: HTTP {response.status_code} - {error_text}\"\n",
    "        \n",
    "        result = response.json()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"      üìä Response keys: {list(result.keys())}\")\n",
    "        \n",
    "        if \"content\" in result and len(result[\"content\"]) > 0:\n",
    "            return result[\"content\"][0][\"text\"]\n",
    "        else:\n",
    "            fallback = result.get(\"completion\", \"No response\")\n",
    "            if debug:\n",
    "                print(f\"      ‚ö†Ô∏è  Using fallback: {fallback[:100]}\")\n",
    "            return fallback\n",
    "    \n",
    "    except requests.exceptions.Timeout:\n",
    "        return f\"ERROR: Request timeout (>90s)\"\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"ERROR: Request failed - {type(e).__name__}: {str(e)}\"\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        return f\"ERROR: Invalid JSON response - {str(e)}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            import traceback\n",
    "            print(f\"\\n      ‚ùå Exception traceback:\")\n",
    "            traceback.print_exc()\n",
    "        return f\"ERROR: {type(e).__name__}: {str(e)}\"\n",
    "\n",
    "def generate_analysis_prompt(prompt_text, scenario_hint=\"\"):\n",
    "    \"\"\"Create analysis prompt for LLM\"\"\"\n",
    "    return f\"\"\"You are an expert in AI-generated image quality assessment and prompt engineering for diffusion models.\n",
    "\n",
    "**Task**: Analyze this logo transformation for Christmas merchandise design.\n",
    "\n",
    "**Prompt used**: \"{prompt_text}\"\n",
    "**Design goal**: {scenario_hint if scenario_hint else \"Holiday merchandise design\"}\n",
    "**Model**: FLUX.1-Kontext-dev (FP16)\n",
    "\n",
    "**Images provided**:\n",
    "1. Input logo (original)\n",
    "2. Generated output (transformed design)\n",
    "3. Word attribution (3 rows: WITH word, WITHOUT word, difference heatmap)\n",
    "4. Evolution grid (diffusion timesteps)\n",
    "5. Timestep attention evolution\n",
    "\n",
    "**Provide concise analysis (2-3 sentences each)**:\n",
    "\n",
    "1. **Prompt Adherence**: Did the model follow instructions? What elements match the prompt?\n",
    "\n",
    "2. **Logo Preservation**: Is the original logo recognizable? Any brand elements lost?\n",
    "\n",
    "3. **Design Suitability**: Would this work for merchandise? Consider printing/manufacturing.\n",
    "\n",
    "4. **Creative Execution**: How well were \"Christmas\"/\"festive\" elements interpreted? Tasteful?\n",
    "\n",
    "5. **Technical Quality**: Any artifacts, distortions, or quality issues?\n",
    "\n",
    "6. **Word Attribution Insights**: Which words (from row 2 of attribution image) had most impact? Any redundant?\n",
    "\n",
    "7. **Prompt Improvements**: 2-3 specific changes to improve output (reference word attribution).\n",
    "\n",
    "Be direct and actionable.\"\"\"\n",
    "\n",
    "def analyze_single_prompt_folder(prompt_folder_path, scenario_name=\"\"):\n",
    "    \"\"\"\n",
    "    Analyze a single prompt folder with all LLMs\n",
    "    \n",
    "    Args:\n",
    "        prompt_folder_path: Path to folder like \"flux_experiments/run_XXX/tshirt_design/prompt_0_base\"\n",
    "        scenario_name: Optional hint like \"t-shirt design\" (auto-detected from path if empty)\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_path = Path(prompt_folder_path)\n",
    "    \n",
    "    if not prompt_path.exists():\n",
    "        print(f\"‚ùå Folder not found: {prompt_path}\")\n",
    "        return\n",
    "    \n",
    "    # Auto-detect scenario from path\n",
    "    if not scenario_name:\n",
    "        parts = prompt_path.parts\n",
    "        if len(parts) >= 2:\n",
    "            scenario_name = parts[-2].replace('_', ' ')\n",
    "    \n",
    "    # Load metadata to get prompt text\n",
    "    metadata_file = prompt_path / \"metadata.json\"\n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file) as f:\n",
    "            metadata = json.load(f)\n",
    "        prompt_text = metadata.get(\"prompt\", \"Unknown prompt\")\n",
    "    else:\n",
    "        prompt_text = \"Prompt not found in metadata\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÅ ANALYZING: {prompt_path.name}\")\n",
    "    print(f\"üìù Prompt: {prompt_text[:80]}...\")\n",
    "    print(f\"üé® Scenario: {scenario_name}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Collect images\n",
    "    images_to_analyze = []\n",
    "    \n",
    "    image_files = [\n",
    "        \"input_image.png\",\n",
    "        \"final_output.png\",\n",
    "        \"word_attribution_complete.png\",\n",
    "        \"evolution_grid.png\"\n",
    "    ]\n",
    "    \n",
    "    for img_name in image_files:\n",
    "        img_path = prompt_path / img_name\n",
    "        if img_path.exists():\n",
    "            images_to_analyze.append(str(img_path))\n",
    "    \n",
    "    # Add timestep evolution if exists\n",
    "    timestep_imgs = list(prompt_path.glob(\"timestep_evolution_*.png\"))\n",
    "    if timestep_imgs:\n",
    "        images_to_analyze.append(str(timestep_imgs[0]))\n",
    "    \n",
    "    print(f\"üì∏ Found {len(images_to_analyze)} images to analyze\\n\")\n",
    "    \n",
    "    # Generate analysis prompt\n",
    "    analysis_prompt = generate_analysis_prompt(prompt_text, scenario_name)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = prompt_path / \"llm_analysis\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Run each LLM\n",
    "    results = {}\n",
    "    \n",
    "    # DEBUG MODE: Enable detailed logging for ALL models initially\n",
    "    debug_mode = True\n",
    "    success_count = 0\n",
    "    \n",
    "    for llm_name, llm_model_id in LLMS_TO_TEST.items():\n",
    "        print(f\"ü§ñ {llm_name:20s} \", end='', flush=True)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = call_bedrock_llm(llm_model_id, analysis_prompt, images_to_analyze, debug=debug_mode)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        if response.startswith(\"ERROR\"):\n",
    "            print(f\"‚ùå Failed ({duration:.1f}s)\")\n",
    "            # Print error details\n",
    "            if debug_mode:\n",
    "                print(f\"   üîç ERROR: {response[:300]}\\n\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Done ({duration:.1f}s, {len(response)} chars)\")\n",
    "            success_count += 1\n",
    "            # Disable debug after first success to reduce spam\n",
    "            if success_count >= 1:\n",
    "                debug_mode = False\n",
    "        \n",
    "        # Save result\n",
    "        result = {\n",
    "            \"llm\": llm_name,\n",
    "            \"model_id\": llm_model_id,\n",
    "            \"prompt\": prompt_text,\n",
    "            \"scenario\": scenario_name,\n",
    "            \"analysis\": response,\n",
    "            \"response_time_seconds\": duration,\n",
    "            \"response_length\": len(response),\n",
    "            \"images_analyzed\": len(images_to_analyze),\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "        \n",
    "        results[llm_name] = result\n",
    "        \n",
    "        # Save individual JSON\n",
    "        with open(output_dir / f\"{llm_name}_analysis.json\", \"w\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        time.sleep(0.5)  # Brief rate limit\n",
    "    \n",
    "    # Create summary markdown\n",
    "    create_summary_report(results, output_dir, prompt_text)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ COMPLETE! Analyzed with {len(results)} LLMs\")\n",
    "    print(f\"üìä Results saved to: {output_dir}\")\n",
    "    print(f\"üìÑ Report: {output_dir}/ANALYSIS_SUMMARY.md\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_summary_report(results, output_dir, prompt_text):\n",
    "    \"\"\"Create markdown summary of all LLM analyses\"\"\"\n",
    "    \n",
    "    report_path = output_dir / \"ANALYSIS_SUMMARY.md\"\n",
    "    \n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(f\"# LLM Analysis Summary\\n\\n\")\n",
    "        f.write(f\"**Prompt**: {prompt_text}\\n\\n\")\n",
    "        f.write(f\"**Generated**: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        # Performance comparison table\n",
    "        f.write(\"## ‚ö° Performance Comparison\\n\\n\")\n",
    "        f.write(\"| LLM | Response Time | Length | Status |\\n\")\n",
    "        f.write(\"|-----|---------------|--------|--------|\\n\")\n",
    "        \n",
    "        for llm_name, result in results.items():\n",
    "            status = \"‚úÖ Success\" if not result['analysis'].startswith(\"ERROR\") else \"‚ùå Failed\"\n",
    "            f.write(f\"| {llm_name} | {result['response_time_seconds']:.1f}s | {result['response_length']} chars | {status} |\\n\")\n",
    "        \n",
    "        f.write(\"\\n---\\n\\n\")\n",
    "        \n",
    "        # Individual analyses\n",
    "        f.write(\"## üìù Detailed Analyses\\n\\n\")\n",
    "        \n",
    "        for llm_name, result in results.items():\n",
    "            f.write(f\"### ü§ñ {llm_name.upper()}\\n\\n\")\n",
    "            f.write(f\"*Model: {result['model_id']}*\\n\\n\")\n",
    "            f.write(f\"{result['analysis']}\\n\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    \n",
    "    print(f\"üìÑ Summary saved: {report_path}\")\n",
    "\n",
    "# ===== BATCH RUNNER (analyze multiple folders) =====\n",
    "def analyze_multiple_prompts(prompt_folders):\n",
    "    \"\"\"\n",
    "    Analyze multiple prompt folders in sequence\n",
    "    \n",
    "    Args:\n",
    "        prompt_folders: List of paths to prompt folders\n",
    "    \"\"\"\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for folder_path in prompt_folders:\n",
    "        results = analyze_single_prompt_folder(folder_path)\n",
    "        all_results[str(folder_path)] = results\n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    print(f\"üéâ Batch complete! Analyzed {len(all_results)} prompt folders\")\n",
    "    return all_results\n",
    "\n",
    "# ===== USAGE EXAMPLES =====\n",
    "\n",
    "# Example 1: Analyze single prompt folder\n",
    "analyze_single_prompt_folder(\n",
    "    \"flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base\"\n",
    ")\n",
    "\n",
    "# Example 2: Analyze all prompts in a scenario\n",
    "\"\"\"\n",
    "scenario_path = Path(\"flux_experiments/run_20251116_013857/tshirt_design\")\n",
    "all_prompts = sorted(scenario_path.glob(\"prompt_*\"))\n",
    "\n",
    "for prompt_folder in all_prompts:\n",
    "    analyze_single_prompt_folder(str(prompt_folder))\n",
    "\"\"\"\n",
    "\n",
    "# Example 3: Analyze specific prompts only\n",
    "\"\"\"\n",
    "analyze_multiple_prompts([\n",
    "    \"flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base\",\n",
    "    \"flux_experiments/run_20251116_013857/tshirt_design/prompt_2_variant2\",\n",
    "    \"flux_experiments/run_20251116_013857/mug_design/prompt_1_variant1\"\n",
    "])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "307f3123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìÅ ANALYZING: prompt_0_base\n",
      "üìù Prompt: adapt logo for holiday t-shirt print with seasonal elements...\n",
      "üé® Scenario: tshirt design\n",
      "======================================================================\n",
      "\n",
      "üì∏ Collecting all images...\n",
      "   ‚úÖ Found 13 images:\n",
      "      1. input_image.png\n",
      "      2. final_output.png\n",
      "      3. word_attribution_complete.png\n",
      "      4. ablated_without_elements.png\n",
      "      5. ablated_without_holiday.png\n",
      "      6. ablated_without_seasonal.png\n",
      "      7. ablated_without_t-shirt.png\n",
      "      8. evolution_grid.png\n",
      "      9. timestep_evolution_seasonal.png\n",
      "      10. step_000_t1000.0.png\n",
      "      11. step_007_t904.5.png\n",
      "      12. step_014_t759.5.png\n",
      "      13. step_021_t512.8.png\n",
      "\n",
      "ü§ñ claude_3_opus        ‚ùå Failed (29.5s)\n",
      "ü§ñ claude_3_sonnet      ‚úÖ Done (27.6s, 4964 chars)\n",
      "ü§ñ claude_3_haiku       ‚úÖ Done (13.6s, 4230 chars)\n",
      "      üìä Overall Score: 9.0/10\n",
      "ü§ñ claude_3.5_sonnet    ‚úÖ Done (21.8s, 3598 chars)\n",
      "ü§ñ claude_3.5_haiku     ‚ùå Failed (1.8s)\n",
      "ü§ñ claude_4_opus        ‚ùå Failed (29.5s)\n",
      "ü§ñ claude_4_sonnet      ‚úÖ Done (24.0s, 5967 chars)\n",
      "ü§ñ claude_4.5_sonnet    ‚ùå Failed (29.5s)\n",
      "ü§ñ claude_4.5_haiku     ‚úÖ Done (25.5s, 9229 chars)\n",
      "üìÑ Summary saved: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/llm_analysis/ANALYSIS_SUMMARY.md\n",
      "üìä Score comparison saved: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/llm_analysis/SCORE_COMPARISON.md\n",
      "üìä CSV saved: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/llm_analysis/scores.csv\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETE! Analyzed with 9 LLMs\n",
      "üìä Results saved to: flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/llm_analysis\n",
      "üìÑ Reports: ANALYSIS_SUMMARY.md, SCORE_COMPARISON.md\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'claude_3_opus': {'llm': 'claude_3_opus',\n",
       "   'model_id': 'us.anthropic.claude-3-opus-20240229-v1:0',\n",
       "   'prompt': 'adapt logo for holiday t-shirt print with seasonal elements',\n",
       "   'scenario': 'tshirt design',\n",
       "   'analysis': 'ERROR: HTTP 504 - {\"message\": \"Endpoint request timed out\"}',\n",
       "   'scores': None,\n",
       "   'response_time_seconds': 29.499578952789307,\n",
       "   'response_length': 59,\n",
       "   'images_analyzed': 13,\n",
       "   'timestamp': 1763278067.358587},\n",
       "  'claude_3_sonnet': {'llm': 'claude_3_sonnet',\n",
       "   'model_id': 'us.anthropic.claude-3-sonnet-20240229-v1:0',\n",
       "   'prompt': 'adapt logo for holiday t-shirt print with seasonal elements',\n",
       "   'scenario': 'tshirt design',\n",
       "   'analysis': '### 1. Prompt Adherence (3-4 sentences)\\nThe final output successfully incorporates seasonal elements like snowflakes, stars, Christmas trees, and poinsettia-like flowers to create a festive holiday design. The original logo is adapted and integrated with these seasonal motifs. However, the prompt specified a \"t-shirt print\", and the final image appears more suited for a graphic or illustration rather than direct printing on apparel.\\n\\n### 2. Logo Preservation (3-4 sentences)\\nThe original geometric logo structure is recognizable in the final output, with the hexagonal shapes and interconnected patterns maintained. However, some finer details and sharp edges appear to have been lost, likely due to the integration of the seasonal elements and the diffusion process. The color gradient from blue to purple is also preserved, albeit with additional yellow accents.\\n\\n### 3. Design Suitability for tshirt design (3-4 sentences)\\nWhile the final design is visually appealing, it may not be ideally suited for direct printing on t-shirts. The intricate details and small elements like snowflakes could pose challenges for printing and may not translate well at smaller scales. Additionally, the color palette, while festive, may not be optimal for apparel printing, which often favors more muted or specific color ranges.\\n\\n### 4. Creative Execution (3-4 sentences)\\nThe interpretation of Christmas and festive elements is well-executed, with recognizable motifs like snowflakes, stars, and stylized trees incorporated harmoniously within the logo structure. The color choices, with the red and green accents, further enhance the festive feel. However, some elements, like the poinsettia-like flowers, appear slightly out of place and could be refined further.\\n\\n### 5. Technical Quality (3-4 sentences)\\nThe evolution grid and snapshots reveal a relatively stable and consistent diffusion process, with the logo structure and seasonal elements emerging gradually. However, there are some visible artifacts and noise in the earlier timesteps, which are mostly resolved in the final output. The attention maps also show a good focus on the relevant areas, although some blurring is evident in the final image.\\n\\n### 6. Word Attribution Analysis (4-5 sentences)\\nThe word attribution visualization and individual ablated images provide valuable insights. The word \"seasonal\" had a strong impact, introducing the festive elements like snowflakes and flowers. \"Holiday\" also played a significant role in shaping the Christmas-themed motifs. Interestingly, the word \"elements\" seemed to have a more localized effect, influencing the distribution and placement of the seasonal components. The heatmaps reveal spatial patterns, with the logo structure being the primary focus and the seasonal elements concentrated around it.\\n\\n### 7. Evolution & Process Insights (3-4 sentences)\\nThe evolution grid and timestep snapshots show a gradual and controlled development of the image, with the logo structure emerging first and the seasonal elements being introduced and refined over time. There are no significant aberrations or unexpected stages, suggesting a stable diffusion process. The attention maps also reveal a consistent focus on the relevant areas throughout the process.\\n\\n### 8. Prompt Improvement Recommendations (4-5 sentences)\\n1. Specify the desired color palette or provide reference images to guide the model towards apparel-friendly colors.\\n2. Introduce a word like \"apparel\" or \"merchandise\" to reinforce the intended use for t-shirt printing, potentially influencing the level of detail and scaling.\\n3. Consider adding a word like \"stylized\" or \"simplified\" to encourage a more streamlined and printable design, reducing intricate details.\\n4. Provide additional context or constraints, such as \"suitable for screen printing\" or \"limited color separations\", to guide the model towards practical considerations for apparel manufacturing.\\n5. Experiment with different prompt structures, such as \"design a holiday t-shirt print featuring the [logo] with seasonal elements like snowflakes and Christmas trees\".\\n\\n### 9. Overall Quality Score\\n- **Prompt Adherence**: 7/10 (Successfully incorporated seasonal elements, but missed the \"t-shirt print\" aspect)\\n- **Logo Preservation**: 7/10 (Recognizable structure, but some details lost)\\n- **Design Suitability**: 6/10 (May not be ideal for direct apparel printing due to intricate details and color palette)\\n- **Creative Execution**: 8/10 (Well-executed festive elements, with some minor refinements needed)\\n- **Technical Quality**: 8/10 (Stable process, good attention, minor artifacts)\\n- **OVERALL SCORE**: 7/10\\n\\nThe design successfully captures the festive spirit and integrates the logo with seasonal elements, but it may require further refinements to be better suited for practical t-shirt printing and apparel manufacturing. The analysis provides actionable insights for prompt engineering and potential improvements.',\n",
       "   'scores': {'prompt_adherence': None,\n",
       "    'logo_preservation': None,\n",
       "    'design_suitability': None,\n",
       "    'creative_execution': None,\n",
       "    'technical_quality': None,\n",
       "    'overall': None},\n",
       "   'response_time_seconds': 27.556897163391113,\n",
       "   'response_length': 4964,\n",
       "   'images_analyzed': 13,\n",
       "   'timestamp': 1763278095.4173567},\n",
       "  'claude_3_haiku': {'llm': 'claude_3_haiku',\n",
       "   'model_id': 'us.anthropic.claude-3-haiku-20240307-v1:0',\n",
       "   'prompt': 'adapt logo for holiday t-shirt print with seasonal elements',\n",
       "   'scenario': 'tshirt design',\n",
       "   'analysis': 'Comprehensive Analysis of the Logo Transformation for Christmas Merchandise Design\\n\\n1. Prompt Adherence:\\nThe final output successfully incorporated the key elements specified in the prompt - \"adapt logo for holiday t-shirt print with seasonal elements\". The design features a stylized geometric logo with vibrant holiday-themed decorations such as snowflakes, stars, and evergreen leaves, effectively transforming the original logo into a festive design suitable for a Christmas t-shirt.\\n\\n2. Logo Preservation:\\nThe original logo\\'s core geometric structure is still recognizable in the final output, though the addition of the seasonal elements has significantly altered the visual appearance. The brand\\'s distinctive hexagonal shape and angular lines are maintained, but the overall aesthetic has shifted from a clean, minimalist design to a more ornate, holiday-inspired look.\\n\\n3. Design Suitability for T-shirt Design:\\nThe transformed logo would work well for a Christmas t-shirt design. The bold, high-contrast colors and simplified shapes would translate effectively to screen printing or other common t-shirt production methods. The design is also scalable, as the core geometric elements would remain legible and visually appealing at various sizes. However, the intricate details of the seasonal elements may pose some challenges in terms of print quality and durability.\\n\\n4. Creative Execution:\\nThe integration of the Christmas-themed decorations, such as the snowflakes, stars, and evergreen leaves, is well-executed and adds a festive touch to the design without overwhelming the original logo. The color palette, featuring a gradient from blue to purple, complements the holiday motifs and creates a cohesive, visually appealing composition.\\n\\n5. Technical Quality:\\nThe overall technical quality of the output is high, with no visible artifacts or distortions. The diffusion process appears to have been stable, as evidenced by the consistent and coherent appearance of the final image. The intermediate stages shown in the evolution grid and timestep snapshots also demonstrate a smooth progression, with the seasonal elements gradually being introduced and refined.\\n\\n6. Word Attribution Analysis:\\nThe word attribution visualization and individual ablated images provide valuable insights into the impact of each keyword. The \"seasonal\" and \"elements\" words had the strongest visual influence, as they directly contributed to the addition of the holiday-themed decorations. The \"holiday\" and \"t-shirt\" keywords also played a role in shaping the final design, though to a lesser extent. The heatmaps suggest that the seasonal elements were primarily concentrated around the central logo structure, creating a cohesive and balanced composition.\\n\\n7. Evolution & Process Insights:\\nThe evolution grid and timestep snapshots reveal a gradual and controlled transformation of the original logo. The early stages focused on preserving the core geometric structure, while the later steps introduced the seasonal elements in a thoughtful and integrated manner. The process appears to have been stable, with no major deviations or inconsistencies observed across the diffusion steps.\\n\\n8. Prompt Improvement Recommendations:\\nTo further enhance the output, the following prompt modifications could be considered:\\n1. Specify a more precise color palette or color scheme (e.g., \"use a festive color palette of blues, purples, and reds\")\\n2. Emphasize the need for a balanced and harmonious integration of the seasonal elements (e.g., \"seamlessly integrate the seasonal elements with the original logo design\")\\n3. Provide additional guidance on the scale and placement of the holiday motifs (e.g., \"ensure the seasonal elements are proportional and do not overwhelm the logo\")\\n\\n9. Overall Quality Score:\\n- Prompt Adherence: 9/10\\n- Logo Preservation: 8/10\\n- Design Suitability: 9/10\\n- Creative Execution: 9/10\\n- Technical Quality: 9/10\\n- OVERALL SCORE: 9/10\\n\\nThe transformed logo design effectively meets the requirements of the prompt, preserves the core brand elements, and is well-suited for a Christmas t-shirt. The creative execution and technical quality are both high, resulting in a visually appealing and cohesive final product.',\n",
       "   'scores': {'prompt_adherence': 9.0,\n",
       "    'logo_preservation': 8.0,\n",
       "    'design_suitability': 9.0,\n",
       "    'creative_execution': 9.0,\n",
       "    'technical_quality': 9.0,\n",
       "    'overall': 9.0},\n",
       "   'response_time_seconds': 13.559071063995361,\n",
       "   'response_length': 4230,\n",
       "   'images_analyzed': 13,\n",
       "   'timestamp': 1763278109.4783041},\n",
       "  'claude_3.5_sonnet': {'llm': 'claude_3.5_sonnet',\n",
       "   'model_id': 'us.anthropic.claude-3-5-sonnet-20241022-v2:0',\n",
       "   'prompt': 'adapt logo for holiday t-shirt print with seasonal elements',\n",
       "   'scenario': 'tshirt design',\n",
       "   'analysis': 'Here\\'s my detailed analysis:\\n\\n### 1. Prompt Adherence\\nThe model successfully adapted the logo for holiday merchandise, incorporating seasonal elements while maintaining the core hexagonal structure. The transformation includes festive elements like snowflakes, stars, and poinsettias. However, the prompt\\'s \"t-shirt print\" aspect is only partially addressed, as some versions show excessive detail that might be challenging for printing.\\n\\n### 2. Logo Preservation\\nThe original geometric hexagonal pattern is well preserved, maintaining its distinctive interconnected structure. The blue-to-purple gradient transition is retained in most versions, showing good fidelity to the source material. The proportions and overall composition remain balanced, though some variations show slight distortions at the edges.\\n\\n### 3. Design Suitability\\nThe design shows good potential for t-shirt printing, particularly the simpler versions with clean lines and clear contrast. The white and red shirt mockups demonstrate versatility across different base colors. However, some versions with intricate details and small elements might pose challenges for screen printing or other commercial printing methods.\\n\\n### 4. Creative Execution\\nThe seasonal elements are tastefully integrated, with snowflakes and poinsettias naturally framing the geometric pattern. The color palette effectively combines traditional holiday reds and greens with the original blue-purple scheme. The decorative elements don\\'t overwhelm the base design, maintaining a good balance between festive and modern.\\n\\n### 5. Technical Quality\\nThe evolution grid shows some noise and artifacts in early stages, but the final outputs are clean and well-defined. Edge consistency is maintained throughout the geometric patterns. Some versions show slight pixelation in the seasonal elements, particularly in the snowflake details.\\n\\n### 6. Word Attribution Analysis\\nThe word \"seasonal\" had the strongest impact, as shown in the attribution maps with clear influence on the decorative elements. \"Holiday\" contributed significantly to the color choices and festive motifs. \"T-shirt\" appears to have influenced the overall composition and scale. The heatmaps show concentrated attention around the edges where seasonal elements were added.\\n\\n### 7. Evolution & Process Insights\\nThe evolution grid shows a stable progression from noise to final image. The geometric pattern emerges early in the process, with seasonal elements being refined in later stages. The cross-attention maps reveal how the model prioritized maintaining the logo\\'s structure while gradually introducing decorative elements.\\n\\n### 8. Prompt Improvement Recommendations\\n- Add \"minimalist holiday elements\" to prevent overcrowding\\n- Specify \"screen-printing friendly\" for better production suitability\\n- Include \"maintain original logo proportions\" for better preservation\\n- Add \"winter color palette\" to guide seasonal color choices\\n- Consider \"symmetric seasonal decoration\" for more balanced composition\\n\\n### 9. Overall Quality Score\\n- **Prompt Adherence**: 8/10\\n- **Logo Preservation**: 9/10\\n- **Design Suitability**: 7/10\\n- **Creative Execution**: 8/10\\n- **Technical Quality**: 8/10\\n- **OVERALL SCORE**: 8/10\\n\\nThe transformation successfully maintains brand identity while adding appropriate seasonal elements. The main areas for improvement are in print production suitability and controlling the complexity of decorative elements. The technical execution is strong, with good stability in the generation process and clear attention to detail in preserving the core logo elements.',\n",
       "   'scores': {'prompt_adherence': None,\n",
       "    'logo_preservation': None,\n",
       "    'design_suitability': None,\n",
       "    'creative_execution': None,\n",
       "    'technical_quality': None,\n",
       "    'overall': None},\n",
       "   'response_time_seconds': 21.798842191696167,\n",
       "   'response_length': 3598,\n",
       "   'images_analyzed': 13,\n",
       "   'timestamp': 1763278131.7791226},\n",
       "  'claude_3.5_haiku': {'llm': 'claude_3.5_haiku',\n",
       "   'model_id': 'us.anthropic.claude-3-5-haiku-20241022-v1:0',\n",
       "   'prompt': 'adapt logo for holiday t-shirt print with seasonal elements',\n",
       "   'scenario': 'tshirt design',\n",
       "   'analysis': 'ERROR: HTTP 500 - {\"error\": \"Bedrock error: An error occurred (ValidationException) when calling the InvokeModel operation: \\'claude-3-5-haiku-20241022\\' does not support image input.\"}',\n",
       "   'scores': None,\n",
       "   'response_time_seconds': 1.7574679851531982,\n",
       "   'response_length': 183,\n",
       "   'images_analyzed': 13,\n",
       "   'timestamp': 1763278134.038247},\n",
       "  'claude_4_opus': {'llm': 'claude_4_opus',\n",
       "   'model_id': 'us.anthropic.claude-opus-4-20250514-v1:0',\n",
       "   'prompt': 'adapt logo for holiday t-shirt print with seasonal elements',\n",
       "   'scenario': 'tshirt design',\n",
       "   'analysis': 'ERROR: HTTP 504 - {\"message\": \"Endpoint request timed out\"}',\n",
       "   'scores': None,\n",
       "   'response_time_seconds': 29.538853406906128,\n",
       "   'response_length': 59,\n",
       "   'images_analyzed': 13,\n",
       "   'timestamp': 1763278164.078695},\n",
       "  'claude_4_sonnet': {'llm': 'claude_4_sonnet',\n",
       "   'model_id': 'us.anthropic.claude-sonnet-4-20250514-v1:0',\n",
       "   'prompt': 'adapt logo for holiday t-shirt print with seasonal elements',\n",
       "   'scenario': 'tshirt design',\n",
       "   'analysis': '## Comprehensive Analysis: Logo Transformation for Christmas Merchandise\\n\\n### 1. Prompt Adherence\\nThe final output successfully implements most prompt requirements, adding clear seasonal elements including snowflakes, Christmas trees, ornaments, and festive foliage around the original geometric logo. The design maintains a holiday aesthetic with traditional red and green Christmas colors complementing the blue geometric structure. However, the adaptation feels more like decoration around the logo rather than a true integration of seasonal elements into the logo itself. The \"t-shirt print\" aspect is reasonably addressed with a clean, printable layout on a neutral background.\\n\\n### 2. Logo Preservation\\nThe original hexagonal geometric logo structure is well-preserved and remains the central focal point of the design. The distinctive interlocking hexagonal pattern and blue-to-purple gradient are maintained with high fidelity, ensuring brand recognition. The logo\\'s scale and positioning allow it to remain prominent while accommodating the seasonal additions. However, the seasonal elements feel somewhat superficial, placed around rather than thoughtfully integrated with the core brand identity, which could be seen as either preserving brand integrity or missing an opportunity for creative fusion.\\n\\n### 3. Design Suitability for T-Shirt Design\\nThis design would work reasonably well for t-shirt printing, with clear vector-style elements that would translate well to screen printing or heat transfer methods. The color palette is practical with distinct red, green, and blue elements that wouldn\\'t require excessive ink colors. The composition is well-centered and appropriately sized for chest placement on apparel. However, the fine details in some snowflakes and smaller decorative elements might lose clarity when printed at smaller sizes or on textured fabrics.\\n\\n### 4. Creative Execution\\nThe Christmas elements are tastefully executed with a good variety of seasonal motifs including geometric snowflakes, stylized Christmas trees, ornamental baubles, and botanical elements. The color choices are appropriately festive while maintaining sophistication, avoiding overly garish holiday clich√©s. The arrangement creates visual balance around the central logo without overwhelming it. The geometric style of the added elements complements the logo\\'s aesthetic, though the execution feels somewhat conservative and could have been more innovative in integrating seasonal themes with the hexagonal motif.\\n\\n### 5. Technical Quality\\nThe technical execution is generally solid with clean vector-style rendering and consistent line weights throughout the design. The evolution grid shows a stable generation process with clear progression from noise to final image without significant artifacts. However, some minor inconsistencies are visible in the smaller decorative elements, and the timestep snapshots reveal occasional slight distortions in the geometric precision. The color gradients are smooth and the overall composition maintains good contrast and readability across all elements.\\n\\n### 6. Word Attribution Analysis\\nThe word attribution analysis reveals that \"seasonal\" and \"elements\" had the strongest visual impact, as evidenced by the dramatic difference in the WITH/WITHOUT comparisons where removing these terms results in minimal decorative additions. The \"holiday\" term appears somewhat redundant with \"seasonal,\" producing similar festive motifs. The heatmaps show concentrated attention around the logo\\'s perimeter where seasonal elements are placed, with \"t-shirt\" influencing the overall composition and background treatment. Interestingly, removing \"t-shirt\" from the prompt results in a more elaborate, pattern-like treatment that might be less suitable for apparel printing, demonstrating this word\\'s important constraining effect on the design complexity.\\n\\n### 7. Evolution & Process Insights\\nThe evolution grid demonstrates a remarkably stable generation process, with the logo structure emerging early and seasonal elements gradually refining around it. The progression from timesteps 000 to 021 shows consistent development without major compositional changes or artifacts. The intermediate stages reveal that the core geometric structure was established early in the process, with decorative elements being added and refined in later stages. This suggests good prompt understanding and stable attention mechanisms throughout the denoising process.\\n\\n### 8. Prompt Improvement Recommendations\\nBased on the analysis, several specific improvements could enhance the output: 1) Add \"integrated geometric snowflake pattern within hexagons\" to better merge seasonal elements with the logo structure rather than just surrounding it. 2) Include \"winter color palette with icy blues and silver accents\" to create more sophisticated seasonal theming beyond traditional red/green. 3) Specify \"scalable vector design optimized for screen printing\" to ensure technical suitability for merchandise production. 4) Replace the redundant \"holiday\" and \"seasonal\" with \"Christmas winter theme\" for more focused seasonal direction. 5) Add \"maintaining brand recognition and geometric integrity\" to better balance seasonal adaptation with logo preservation.\\n\\n### 9. Overall Quality Score\\n- **Prompt Adherence**: 7/10 (Good implementation but somewhat literal interpretation)\\n- **Logo Preservation**: 8/10 (Excellent brand recognition maintenance)\\n- **Design Suitability**: 7/10 (Printable but some detail concerns at small sizes)\\n- **Creative Execution**: 6/10 (Safe and tasteful but could be more innovative)\\n- **Technical Quality**: 8/10 (Clean execution with minor geometric inconsistencies)\\n- **OVERALL SCORE**: 7.2/10\\n\\nThe design successfully creates a festive adaptation suitable for holiday merchandise while preserving brand identity, though it could benefit from more creative integration of seasonal elements with the core logo structure.',\n",
       "   'scores': {'prompt_adherence': None,\n",
       "    'logo_preservation': None,\n",
       "    'design_suitability': None,\n",
       "    'creative_execution': None,\n",
       "    'technical_quality': None,\n",
       "    'overall': None},\n",
       "   'response_time_seconds': 23.95789122581482,\n",
       "   'response_length': 5967,\n",
       "   'images_analyzed': 13,\n",
       "   'timestamp': 1763278188.5386662},\n",
       "  'claude_4.5_sonnet': {'llm': 'claude_4.5_sonnet',\n",
       "   'model_id': 'us.anthropic.claude-sonnet-4-5-20250929-v1:0',\n",
       "   'prompt': 'adapt logo for holiday t-shirt print with seasonal elements',\n",
       "   'scenario': 'tshirt design',\n",
       "   'analysis': 'ERROR: HTTP 504 - {\"message\": \"Endpoint request timed out\"}',\n",
       "   'scores': None,\n",
       "   'response_time_seconds': 29.49755311012268,\n",
       "   'response_length': 59,\n",
       "   'images_analyzed': 13,\n",
       "   'timestamp': 1763278218.5378015},\n",
       "  'claude_4.5_haiku': {'llm': 'claude_4.5_haiku',\n",
       "   'model_id': 'us.anthropic.claude-haiku-4-5-20251001-v1:0',\n",
       "   'prompt': 'adapt logo for holiday t-shirt print with seasonal elements',\n",
       "   'scenario': 'tshirt design',\n",
       "   'analysis': '# Comprehensive Analysis: Holiday Logo Transformation for T-Shirt Design\\n\\n## 1. Prompt Adherence\\n\\nThe final output demonstrates **strong adherence to the core prompt requirements**. The geometric hexagonal logo is clearly present as the central design element, and multiple seasonal decorations have been successfully integrated‚Äîincluding red and green star-burst flowers, orange/yellow stars, green foliage with leaves, and brown botanical elements. However, the prompt\\'s implicit expectation of a \"print-ready\" design with clear color separation and manufacturing viability was only partially met. The seasonal elements, while present, create a somewhat cluttered composition that may challenge traditional screen-printing workflows. The color palette (blue hexagons, red/green/orange/yellow accents) is festive but introduces complexity for multi-color printing.\\n\\n## 2. Logo Preservation\\n\\nThe original geometric hexagonal logo is **exceptionally well-preserved** in the output. The blue-to-purple gradient structure, the nested hexagonal pattern, and the 3D isometric perspective remain intact and immediately recognizable. The logo maintains its original proportions and positioning as the dominant central element. However, the integration of seasonal elements around and occasionally overlapping the logo creates visual competition‚Äîthe decorative elements don\\'t feel subordinate but rather co-equal in visual weight, which slightly diminishes the logo\\'s authority as the primary brand mark.\\n\\n## 3. Design Suitability for T-Shirt Merchandise\\n\\n**Moderate suitability with manufacturing concerns**. The design works conceptually for holiday merchandise and would appeal to consumers seeking festive apparel. However, practical printing challenges emerge: the gradient hexagon requires precise color registration, the small decorative elements (particularly the delicate star shapes and leaf details) may not reproduce cleanly at typical t-shirt print sizes, and the overall color count (minimum 4-5 separations) increases production costs significantly. The cream/off-white background is practical, but the design density leaves minimal breathing room. For direct-to-garment printing, this would work well; for screen printing, simplification would be necessary.\\n\\n## 4. Creative Execution\\n\\nThe festive interpretation is **tasteful and well-executed**. The seasonal elements‚Äîpoinsettia-like flowers, snowflake-inspired stars, holly-like foliage, and ornamental berries‚Äîare recognizable and thematically appropriate without being clich√©d. The color choices (traditional Christmas reds and greens balanced with warm golds) feel cohesive. The spatial distribution of elements around the logo creates visual balance, with heavier elements anchoring the bottom corners and lighter elements floating around the top. The design successfully bridges the gap between geometric modernism (the logo) and organic holiday aesthetics, though this juxtaposition could be more intentional.\\n\\n## 5. Technical Quality\\n\\n**Excellent technical execution with minimal artifacts**. Examining the evolution grid and timestep snapshots reveals a stable, progressive refinement process. The final output shows clean line work, smooth color transitions in the gradient hexagon, and well-defined decorative elements with minimal noise or distortion. The intermediate stages (Steps 000, 007, 014, 021) demonstrate controlled denoising‚Äîthe logo structure emerges clearly by Step 007, and decorative elements progressively sharpen through Step 021. No significant color bleeding, edge artifacts, or structural distortions are visible. The generation appears to have converged smoothly without oscillation or instability.\\n\\n## 6. Word Attribution Analysis\\n\\n**Critical findings from ablation study**:\\n\\n- **\"seasonal\"** (top-left ablation): Removal eliminates the festive flower elements and reduces color diversity. The heatmap shows strong activation in the lower-left and upper-right quadrants, indicating this word drives the poinsettia and foliage placement. **Impact: Very High**\\n\\n- **\"elements\"** (top-center ablation): Removal results in a sparser composition with fewer decorative objects. The heatmap shows distributed activation across the entire composition, suggesting this word controls object density and variety. **Impact: High**\\n\\n- **\"holiday\"** (top-right ablation): Removal produces a design that retains the logo but loses thematic coherence‚Äîfewer red/green color choices and less festive character overall. The heatmap shows moderate activation throughout, particularly in color selection regions. **Impact: Moderate-High**\\n\\n- **\"t-shirt\"** (bottom-right ablation): Removal shows the most dramatic change‚Äîthe design becomes more illustration-like with less consideration for print constraints and composition balance. The heatmap reveals strong activation in spatial arrangement and background treatment. **Impact: High**\\n\\nThe **difference maps** (bottom row) reveal that \"seasonal\" and \"elements\" have the strongest visual impact (brightest heatmaps), while \"holiday\" and \"t-shirt\" provide contextual refinement. Notably, **no words appear redundant**‚Äîeach contributes distinct visual information. The spatial patterns show \"seasonal\" concentrating on decorative object placement, while \"t-shirt\" influences overall composition and printability considerations.\\n\\n## 7. Evolution & Process Insights\\n\\nThe **diffusion process demonstrates exceptional stability and coherence**. At Step 000 (t=1000.0), the image is pure noise with no discernible structure. By Step 007 (t=904.5), the hexagonal logo structure is already clearly visible, indicating the model prioritizes this primary element early. Step 014 (t=759.5) shows the logo fully refined with color gradients established and initial decorative elements appearing. Step 021 (t=512.8) represents near-completion, with all seasonal elements sharp and well-positioned. The cross-attention maps for \"seasonal\" show progressive focus refinement‚Äîearly steps show broad activation, while later steps concentrate attention on specific decorative regions. This suggests the model first establishes the logo structure, then progressively adds contextual seasonal elements‚Äîan intelligent hierarchical generation strategy.\\n\\n## 8. Prompt Improvement Recommendations\\n\\nBased on the ablation analysis and output quality, here are **5 specific prompt modifications**:\\n\\n1. **Add manufacturing specificity**: Change to *\"adapt logo for holiday t-shirt print with seasonal elements, optimized for 4-color screen printing\"*. The current output would benefit from explicit constraint guidance to reduce color count and improve printability.\\n\\n2. **Enhance spatial hierarchy**: Modify to *\"adapt logo for holiday t-shirt print with seasonal elements arranged around the logo, not overlapping\"*. The current design has decorative elements occasionally obscuring the logo; explicit spatial guidance would improve brand clarity.\\n\\n3. **Specify seasonal palette**: Change to *\"adapt logo for holiday t-shirt print with red, green, and gold seasonal elements\"*. This would reduce the orange/yellow variation and create more cohesive color harmony.\\n\\n4. **Add style direction**: Modify to *\"adapt logo for holiday t-shirt print with minimalist seasonal elements in a modern geometric style\"*. This would better align the organic decorative elements with the geometric logo aesthetic.\\n\\n5. **Include size/scale guidance**: Change to *\"adapt logo for holiday t-shirt print with small, delicate seasonal elements that remain crisp at 12-inch print size\"*. This would ensure decorative elements maintain printability at actual merchandise scale.\\n\\n## 9. Overall Quality Scores\\n\\n| Criterion | Score | Rationale |\\n|-----------|-------|-----------|\\n| **Prompt Adherence** | 8.5/10 | All major elements present; minor gaps in manufacturing optimization |\\n| **Logo Preservation** | 9/10 | Excellent structural and aesthetic retention; minimal degradation |\\n| **Design Suitability** | 7/10 | Conceptually strong; practical manufacturing concerns reduce score |\\n| **Creative Execution** | 8.5/10 | Tasteful, thematically appropriate; slight visual competition between elements |\\n| **Technical Quality** | 9/10 | Clean rendering, stable generation, minimal artifacts |\\n| **Word Attribution Clarity** | 8/10 | Clear differentiation between word impacts; all words contribute meaningfully |\\n| **OVERALL SCORE** | **8.3/10** | Strong execution with minor refinements needed for production readiness |\\n\\n---\\n\\n## Summary\\n\\nThis is a **high-quality, well-executed design transformation** that successfully balances logo preservation with festive enhancement. The AI model demonstrated sophisticated understanding of spatial hierarchy, thematic integration, and technical constraints. The primary opportunity for improvement lies in **manufacturing optimization**‚Äîadding explicit guidance about color separation, print size, and spatial constraints would elevate this from \"excellent concept\" to \"production-ready merchandise design.\" The word attribution analysis reveals a well-calibrated prompt where each component contributes meaningfully without redundancy, suggesting the original prompt was well-structured despite room for refinement.',\n",
       "   'scores': {'prompt_adherence': None,\n",
       "    'logo_preservation': None,\n",
       "    'design_suitability': None,\n",
       "    'creative_execution': None,\n",
       "    'technical_quality': None,\n",
       "    'overall': None},\n",
       "   'response_time_seconds': 25.45812749862671,\n",
       "   'response_length': 9229,\n",
       "   'images_analyzed': 13,\n",
       "   'timestamp': 1763278244.4980793}},\n",
       " {'claude_3_sonnet': {'prompt_adherence': None,\n",
       "   'logo_preservation': None,\n",
       "   'design_suitability': None,\n",
       "   'creative_execution': None,\n",
       "   'technical_quality': None,\n",
       "   'overall': None},\n",
       "  'claude_3_haiku': {'prompt_adherence': 9.0,\n",
       "   'logo_preservation': 8.0,\n",
       "   'design_suitability': 9.0,\n",
       "   'creative_execution': 9.0,\n",
       "   'technical_quality': 9.0,\n",
       "   'overall': 9.0},\n",
       "  'claude_3.5_sonnet': {'prompt_adherence': None,\n",
       "   'logo_preservation': None,\n",
       "   'design_suitability': None,\n",
       "   'creative_execution': None,\n",
       "   'technical_quality': None,\n",
       "   'overall': None},\n",
       "  'claude_4_sonnet': {'prompt_adherence': None,\n",
       "   'logo_preservation': None,\n",
       "   'design_suitability': None,\n",
       "   'creative_execution': None,\n",
       "   'technical_quality': None,\n",
       "   'overall': None},\n",
       "  'claude_4.5_haiku': {'prompt_adherence': None,\n",
       "   'logo_preservation': None,\n",
       "   'design_suitability': None,\n",
       "   'creative_execution': None,\n",
       "   'technical_quality': None,\n",
       "   'overall': None}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comprehensive Single-Prompt LLM Analysis with Scoring\n",
    "Uses ALL generated images and provides quantitative comparison metrics\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# ===== AWS BEDROCK CONFIGURATION =====\n",
    "API_ENDPOINT = \"https://ctwa92wg1b.execute-api.us-east-1.amazonaws.com/prod/invoke\"\n",
    "TEAM_ID = \"team_the_great_hack_2025_022\"\n",
    "API_TOKEN = \"znqXT5zCmCynAx-kyx_hldrxvSeyaWvxzx55vB5mfNg\"\n",
    "\n",
    "# ===== ALL CLAUDE MODELS =====\n",
    "LLMS_TO_TEST = {\n",
    "    \"claude_3_opus\": \"us.anthropic.claude-3-opus-20240229-v1:0\",\n",
    "    \"claude_3_sonnet\": \"us.anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"claude_3_haiku\": \"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    \"claude_3.5_sonnet\": \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "    \"claude_3.5_haiku\": \"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    \"claude_4_opus\": \"us.anthropic.claude-opus-4-20250514-v1:0\",\n",
    "    \"claude_4_sonnet\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "    \"claude_4.5_sonnet\": \"us.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
    "    \"claude_4.5_haiku\": \"us.anthropic.claude-haiku-4-5-20251001-v1:0\",\n",
    "}\n",
    "\n",
    "# ===== IMAGE PROCESSING =====\n",
    "def resize_image_if_needed(image_path, max_dimension=1200, quality=80):\n",
    "    \"\"\"Resize and optimize image for API\"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.mode not in ('RGB', 'L'):\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            width, height = img.size\n",
    "            \n",
    "            if max(width, height) > max_dimension:\n",
    "                if width > height:\n",
    "                    new_width = max_dimension\n",
    "                    new_height = int(height * (max_dimension / width))\n",
    "                else:\n",
    "                    new_height = max_dimension\n",
    "                    new_width = int(width * (max_dimension / height))\n",
    "                \n",
    "                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format='JPEG', quality=quality, optimize=True)\n",
    "            buffer.seek(0)\n",
    "            \n",
    "            img_b64 = base64.b64encode(buffer.read()).decode('utf-8')\n",
    "            return img_b64, 'image/jpeg'\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to process {image_path}: {str(e)}\")\n",
    "\n",
    "# ===== API CALL =====\n",
    "def call_bedrock_llm(model_id, prompt, images=None):\n",
    "    \"\"\"Call AWS Bedrock via API\"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-api-key\": API_TOKEN\n",
    "    }\n",
    "    \n",
    "    content = []\n",
    "    \n",
    "    if images:\n",
    "        for img_path in images:\n",
    "            try:\n",
    "                img_b64, media_type = resize_image_if_needed(img_path, max_dimension=1200, quality=80)\n",
    "                content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": media_type,\n",
    "                        \"data\": img_b64\n",
    "                    }\n",
    "                })\n",
    "            except Exception as e:\n",
    "                return f\"ERROR: Image encoding failed for {img_path}: {str(e)}\"\n",
    "    \n",
    "    content.append({\"type\": \"text\", \"text\": prompt})\n",
    "    \n",
    "    payload = {\n",
    "        \"team_id\": TEAM_ID,\n",
    "        \"api_token\": API_TOKEN,\n",
    "        \"model\": model_id,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": content}],\n",
    "        \"max_tokens\": 3000,  # Increased for comprehensive analysis\n",
    "        \"temperature\": 0.3\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_ENDPOINT, headers=headers, json=payload, timeout=120)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return f\"ERROR: HTTP {response.status_code} - {response.text[:500]}\"\n",
    "        \n",
    "        result = response.json()\n",
    "        \n",
    "        if \"content\" in result and len(result[\"content\"]) > 0:\n",
    "            return result[\"content\"][0][\"text\"]\n",
    "        else:\n",
    "            return result.get(\"completion\", \"No response\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {type(e).__name__}: {str(e)}\"\n",
    "\n",
    "# ===== COMPREHENSIVE ANALYSIS PROMPT =====\n",
    "def generate_comprehensive_analysis_prompt(prompt_text, scenario_hint, image_count):\n",
    "    \"\"\"Create detailed analysis prompt that references ALL images\"\"\"\n",
    "    return f\"\"\"You are an expert in AI-generated image quality assessment and prompt engineering for diffusion models.\n",
    "\n",
    "**Task**: Provide a comprehensive analysis of this logo transformation for Christmas merchandise design.\n",
    "\n",
    "**Prompt used**: \"{prompt_text}\"\n",
    "**Design goal**: {scenario_hint}\n",
    "**Model**: FLUX.1-Kontext-dev (FP16)\n",
    "\n",
    "**Images provided ({image_count} total)**:\n",
    "1. **Input logo** - Original design\n",
    "2. **Final output** - Transformed result\n",
    "3. **Word attribution (3-row visualization)** - Shows WITH/WITHOUT/HEATMAP for each key word\n",
    "4. **Individual ablated outputs** - Separate images showing result when each word is removed\n",
    "5. **Evolution grid** - Diffusion process across timesteps\n",
    "6. **Timestep evolution** - How attention changes over denoising steps\n",
    "7. **Snapshots** - Intermediate generation stages\n",
    "\n",
    "**Provide detailed analysis**:\n",
    "\n",
    "### 1. Prompt Adherence (3-4 sentences)\n",
    "Examine the final output and compare to the prompt. Which specific elements were successfully implemented? What was missing or misinterpreted?\n",
    "\n",
    "### 2. Logo Preservation (3-4 sentences)\n",
    "Looking at input vs output, is the original logo recognizable? Which brand elements were maintained vs lost? Reference specific visual details.\n",
    "\n",
    "### 3. Design Suitability for {scenario_hint} (3-4 sentences)\n",
    "Would this work for actual merchandise? Consider printing, colors, scalability, and practical manufacturing constraints.\n",
    "\n",
    "### 4. Creative Execution (3-4 sentences)\n",
    "How well were Christmas/festive elements interpreted? Are they tasteful and appropriate? Reference specific design choices visible in the images.\n",
    "\n",
    "### 5. Technical Quality (3-4 sentences)\n",
    "Examine all images (especially evolution grid and snapshots) for artifacts, distortions, consistency issues, or quality problems.\n",
    "\n",
    "### 6. Word Attribution Analysis (4-5 sentences)\n",
    "Study the word attribution visualization AND individual ablated images. Which words had the strongest visual impact? Were any redundant? What spatial patterns do you see in the heatmaps? Reference specific words and their effects.\n",
    "\n",
    "### 7. Evolution & Process Insights (3-4 sentences)\n",
    "Looking at the evolution grid and timestep snapshots, how did the image develop? Were there any interesting intermediate stages? Did the process appear stable?\n",
    "\n",
    "### 8. Prompt Improvement Recommendations (4-5 sentences)\n",
    "Based on word attribution and ablation results, provide 3-5 specific prompt modifications that would improve the output. Be concrete and actionable.\n",
    "\n",
    "### 9. Overall Quality Score\n",
    "Provide a score out of 10 for:\n",
    "- **Prompt Adherence**: X/10\n",
    "- **Logo Preservation**: X/10\n",
    "- **Design Suitability**: X/10\n",
    "- **Creative Execution**: X/10\n",
    "- **Technical Quality**: X/10\n",
    "- **OVERALL SCORE**: X/10\n",
    "\n",
    "**Be thorough, reference specific images, and provide actionable insights.**\"\"\"\n",
    "\n",
    "# ===== COLLECT ALL IMAGES =====\n",
    "def collect_all_images(prompt_path):\n",
    "    \"\"\"\n",
    "    Collect ALL images from the prompt folder for comprehensive analysis\n",
    "    \n",
    "    Returns:\n",
    "        List of image paths in priority order\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    \n",
    "    # Priority images (always include first)\n",
    "    priority_files = [\n",
    "        \"input_image.png\",\n",
    "        \"final_output.png\",\n",
    "        \"word_attribution_complete.png\"\n",
    "    ]\n",
    "    \n",
    "    for img_name in priority_files:\n",
    "        img_path = prompt_path / img_name\n",
    "        if img_path.exists():\n",
    "            images.append(str(img_path))\n",
    "    \n",
    "    # Individual ablated images (sorted alphabetically)\n",
    "    ablated_imgs = sorted(prompt_path.glob(\"ablated_without_*.png\"))\n",
    "    for img in ablated_imgs:\n",
    "        images.append(str(img))\n",
    "    \n",
    "    # Evolution grid\n",
    "    evolution_img = prompt_path / \"evolution_grid.png\"\n",
    "    if evolution_img.exists():\n",
    "        images.append(str(evolution_img))\n",
    "    \n",
    "    # Timestep evolution\n",
    "    timestep_imgs = sorted(prompt_path.glob(\"timestep_evolution_*.png\"))\n",
    "    for img in timestep_imgs:\n",
    "        images.append(str(img))\n",
    "    \n",
    "    # Snapshots folder (if exists)\n",
    "    snapshot_dir = prompt_path / \"snapshots\"\n",
    "    if snapshot_dir.exists():\n",
    "        snapshot_imgs = sorted(snapshot_dir.glob(\"*.png\"))\n",
    "        # Limit to first 5 snapshots to avoid overwhelming the model\n",
    "        for img in snapshot_imgs[:5]:\n",
    "            images.append(str(img))\n",
    "    \n",
    "    return images\n",
    "\n",
    "# ===== EXTRACT SCORES =====\n",
    "def extract_scores_from_analysis(analysis_text):\n",
    "    \"\"\"\n",
    "    Extract numerical scores from LLM analysis\n",
    "    \n",
    "    Returns:\n",
    "        Dict of scores or None if extraction fails\n",
    "    \"\"\"\n",
    "    scores = {\n",
    "        \"prompt_adherence\": None,\n",
    "        \"logo_preservation\": None,\n",
    "        \"design_suitability\": None,\n",
    "        \"creative_execution\": None,\n",
    "        \"technical_quality\": None,\n",
    "        \"overall\": None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Look for score patterns like \"X/10\" or \"Score: X\"\n",
    "        import re\n",
    "        \n",
    "        # Define patterns for each category\n",
    "        patterns = {\n",
    "            \"prompt_adherence\": r\"Prompt Adherence[:\\s]*(\\d+(?:\\.\\d+)?)\\s*/\\s*10\",\n",
    "            \"logo_preservation\": r\"Logo Preservation[:\\s]*(\\d+(?:\\.\\d+)?)\\s*/\\s*10\",\n",
    "            \"design_suitability\": r\"Design Suitability[:\\s]*(\\d+(?:\\.\\d+)?)\\s*/\\s*10\",\n",
    "            \"creative_execution\": r\"Creative Execution[:\\s]*(\\d+(?:\\.\\d+)?)\\s*/\\s*10\",\n",
    "            \"technical_quality\": r\"Technical Quality[:\\s]*(\\d+(?:\\.\\d+)?)\\s*/\\s*10\",\n",
    "            \"overall\": r\"OVERALL SCORE[:\\s]*(\\d+(?:\\.\\d+)?)\\s*/\\s*10\"\n",
    "        }\n",
    "        \n",
    "        for category, pattern in patterns.items():\n",
    "            match = re.search(pattern, analysis_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                scores[category] = float(match.group(1))\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è  Score extraction failed: {e}\")\n",
    "        return scores\n",
    "\n",
    "# ===== MAIN ANALYSIS FUNCTION =====\n",
    "def analyze_single_prompt_folder(prompt_folder_path, scenario_name=\"\"):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis with ALL images and scoring\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_path = Path(prompt_folder_path)\n",
    "    \n",
    "    if not prompt_path.exists():\n",
    "        print(f\"‚ùå Folder not found: {prompt_path}\")\n",
    "        return\n",
    "    \n",
    "    # Auto-detect scenario\n",
    "    if not scenario_name:\n",
    "        parts = prompt_path.parts\n",
    "        if len(parts) >= 2:\n",
    "            scenario_name = parts[-2].replace('_', ' ')\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata_file = prompt_path / \"metadata.json\"\n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file) as f:\n",
    "            metadata = json.load(f)\n",
    "        prompt_text = metadata.get(\"prompt\", \"Unknown prompt\")\n",
    "    else:\n",
    "        prompt_text = \"Prompt not found\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÅ ANALYZING: {prompt_path.name}\")\n",
    "    print(f\"üìù Prompt: {prompt_text[:80]}...\")\n",
    "    print(f\"üé® Scenario: {scenario_name}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Collect ALL images\n",
    "    print(\"üì∏ Collecting all images...\")\n",
    "    images_to_analyze = collect_all_images(prompt_path)\n",
    "    \n",
    "    print(f\"   ‚úÖ Found {len(images_to_analyze)} images:\")\n",
    "    for i, img in enumerate(images_to_analyze, 1):\n",
    "        img_name = Path(img).name\n",
    "        print(f\"      {i}. {img_name}\")\n",
    "    print()\n",
    "    \n",
    "    # Generate comprehensive analysis prompt\n",
    "    analysis_prompt = generate_comprehensive_analysis_prompt(\n",
    "        prompt_text, scenario_name, len(images_to_analyze)\n",
    "    )\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = prompt_path / \"llm_analysis\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Run each LLM\n",
    "    results = {}\n",
    "    all_scores = {}\n",
    "    \n",
    "    for llm_name, llm_model_id in LLMS_TO_TEST.items():\n",
    "        print(f\"ü§ñ {llm_name:20s} \", end='', flush=True)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = call_bedrock_llm(llm_model_id, analysis_prompt, images_to_analyze)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        if response.startswith(\"ERROR\"):\n",
    "            print(f\"‚ùå Failed ({duration:.1f}s)\")\n",
    "            scores = None\n",
    "        else:\n",
    "            print(f\"‚úÖ Done ({duration:.1f}s, {len(response)} chars)\")\n",
    "            # Extract scores\n",
    "            scores = extract_scores_from_analysis(response)\n",
    "            all_scores[llm_name] = scores\n",
    "            if scores and scores['overall']:\n",
    "                print(f\"      üìä Overall Score: {scores['overall']}/10\")\n",
    "        \n",
    "        # Save result\n",
    "        result = {\n",
    "            \"llm\": llm_name,\n",
    "            \"model_id\": llm_model_id,\n",
    "            \"prompt\": prompt_text,\n",
    "            \"scenario\": scenario_name,\n",
    "            \"analysis\": response,\n",
    "            \"scores\": scores,\n",
    "            \"response_time_seconds\": duration,\n",
    "            \"response_length\": len(response),\n",
    "            \"images_analyzed\": len(images_to_analyze),\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "        \n",
    "        results[llm_name] = result\n",
    "        \n",
    "        # Save individual JSON\n",
    "        with open(output_dir / f\"{llm_name}_analysis.json\", \"w\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Create comprehensive reports\n",
    "    create_comprehensive_report(results, all_scores, output_dir, prompt_text)\n",
    "    create_score_comparison_matrix(all_scores, output_dir)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ COMPLETE! Analyzed with {len(results)} LLMs\")\n",
    "    print(f\"üìä Results saved to: {output_dir}\")\n",
    "    print(f\"üìÑ Reports: ANALYSIS_SUMMARY.md, SCORE_COMPARISON.md\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return results, all_scores\n",
    "\n",
    "# ===== REPORTING =====\n",
    "def create_comprehensive_report(results, all_scores, output_dir, prompt_text):\n",
    "    \"\"\"Create detailed markdown report\"\"\"\n",
    "    \n",
    "    report_path = output_dir / \"ANALYSIS_SUMMARY.md\"\n",
    "    \n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(f\"# Comprehensive LLM Analysis Report\\n\\n\")\n",
    "        f.write(f\"**Prompt**: {prompt_text}\\n\\n\")\n",
    "        f.write(f\"**Generated**: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        # Performance table\n",
    "        f.write(\"## ‚ö° Performance & Scoring Overview\\n\\n\")\n",
    "        f.write(\"| LLM | Response Time | Length | Overall Score | Status |\\n\")\n",
    "        f.write(\"|-----|---------------|--------|---------------|--------|\\n\")\n",
    "        \n",
    "        for llm_name, result in results.items():\n",
    "            status = \"‚úÖ\" if not result['analysis'].startswith(\"ERROR\") else \"‚ùå\"\n",
    "            score = result['scores']['overall'] if result['scores'] and result['scores']['overall'] else \"N/A\"\n",
    "            f.write(f\"| {llm_name} | {result['response_time_seconds']:.1f}s | {result['response_length']} chars | {score}/10 | {status} |\\n\")\n",
    "        \n",
    "        f.write(\"\\n---\\n\\n\")\n",
    "        \n",
    "        # Individual analyses\n",
    "        f.write(\"## üìù Detailed Analyses\\n\\n\")\n",
    "        \n",
    "        for llm_name, result in results.items():\n",
    "            f.write(f\"### ü§ñ {llm_name.upper()}\\n\\n\")\n",
    "            f.write(f\"*Model: {result['model_id']}*\\n\\n\")\n",
    "            \n",
    "            if result['scores']:\n",
    "                f.write(f\"**Scores**:\\n\")\n",
    "                for category, score in result['scores'].items():\n",
    "                    if score is not None:\n",
    "                        f.write(f\"- {category.replace('_', ' ').title()}: {score}/10\\n\")\n",
    "                f.write(\"\\n\")\n",
    "            \n",
    "            f.write(f\"**Analysis**:\\n\\n\")\n",
    "            f.write(f\"{result['analysis']}\\n\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    \n",
    "    print(f\"üìÑ Summary saved: {report_path}\")\n",
    "\n",
    "def create_score_comparison_matrix(all_scores, output_dir):\n",
    "    \"\"\"Create score comparison matrix across all LLMs (no tabulate dependency)\"\"\"\n",
    "    \n",
    "    report_path = output_dir / \"SCORE_COMPARISON.md\"\n",
    "    \n",
    "    # Build comparison data\n",
    "    score_data = []\n",
    "    for llm_name, scores in all_scores.items():\n",
    "        if scores:\n",
    "            row = {\"LLM\": llm_name}\n",
    "            row.update(scores)\n",
    "            score_data.append(row)\n",
    "    \n",
    "    if not score_data:\n",
    "        print(\"‚ö†Ô∏è  No scores to compare\")\n",
    "        return\n",
    "    \n",
    "    # Convert to simple dict structure for easy processing\n",
    "    df_data = pd.DataFrame(score_data)\n",
    "    \n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(\"# LLM Score Comparison Matrix\\n\\n\")\n",
    "        f.write(f\"**Generated**: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        # Overall ranking\n",
    "        if 'overall' in df_data.columns:\n",
    "            df_sorted = df_data.sort_values('overall', ascending=False)\n",
    "            f.write(\"## üèÜ Overall Ranking\\n\\n\")\n",
    "            f.write(\"| Rank | LLM | Overall Score |\\n\")\n",
    "            f.write(\"|------|-----|---------------|\\n\")\n",
    "            rank = 1\n",
    "            for _, row in df_sorted.iterrows():\n",
    "                if row['overall'] is not None:\n",
    "                    f.write(f\"| {rank} | {row['LLM']} | {row['overall']:.1f}/10 |\\n\")\n",
    "                    rank += 1\n",
    "            f.write(\"\\n---\\n\\n\")\n",
    "        \n",
    "        # Category breakdown (manual markdown table)\n",
    "        f.write(\"## üìä Category Breakdown\\n\\n\")\n",
    "        \n",
    "        # Build header\n",
    "        categories = ['LLM', 'prompt_adherence', 'logo_preservation', 'design_suitability', \n",
    "                     'creative_execution', 'technical_quality', 'overall']\n",
    "        \n",
    "        # Nice column names\n",
    "        col_names = {\n",
    "            'LLM': 'LLM',\n",
    "            'prompt_adherence': 'Prompt',\n",
    "            'logo_preservation': 'Logo',\n",
    "            'design_suitability': 'Design',\n",
    "            'creative_execution': 'Creative',\n",
    "            'technical_quality': 'Technical',\n",
    "            'overall': 'Overall'\n",
    "        }\n",
    "        \n",
    "        # Write header\n",
    "        header = \"| \" + \" | \".join(col_names[cat] for cat in categories) + \" |\"\n",
    "        separator = \"|\" + \"|\".join([\"------\" for _ in categories]) + \"|\"\n",
    "        f.write(header + \"\\n\")\n",
    "        f.write(separator + \"\\n\")\n",
    "        \n",
    "        # Write rows\n",
    "        for _, row in df_data.iterrows():\n",
    "            values = []\n",
    "            for cat in categories:\n",
    "                if cat == 'LLM':\n",
    "                    values.append(str(row.get(cat, 'N/A')))\n",
    "                else:\n",
    "                    val = row.get(cat, None)\n",
    "                    if val is not None:\n",
    "                        values.append(f\"{val:.1f}\")\n",
    "                    else:\n",
    "                        values.append(\"N/A\")\n",
    "            \n",
    "            f.write(\"| \" + \" | \".join(values) + \" |\\n\")\n",
    "        \n",
    "        f.write(\"\\n---\\n\\n\")\n",
    "        \n",
    "        # Statistics (manual calculation)\n",
    "        f.write(\"## üìà Statistical Summary\\n\\n\")\n",
    "        \n",
    "        numeric_cols = ['prompt_adherence', 'logo_preservation', 'design_suitability',\n",
    "                       'creative_execution', 'technical_quality', 'overall']\n",
    "        \n",
    "        f.write(\"| Category | Mean | Std | Min | Max |\\n\")\n",
    "        f.write(\"|----------|------|-----|-----|-----|\\n\")\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if col in df_data.columns:\n",
    "                values = df_data[col].dropna()\n",
    "                if len(values) > 0:\n",
    "                    col_display = col.replace('_', ' ').title()\n",
    "                    f.write(f\"| {col_display} | {values.mean():.2f} | {values.std():.2f} | \"\n",
    "                           f\"{values.min():.1f} | {values.max():.1f} |\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"üìä Score comparison saved: {report_path}\")\n",
    "    \n",
    "    # Also save as CSV for easy analysis\n",
    "    csv_path = output_dir / \"scores.csv\"\n",
    "    df_data.to_csv(csv_path, index=False)\n",
    "    print(f\"üìä CSV saved: {csv_path}\")\n",
    "\n",
    "# ===== USAGE =====\n",
    "analyze_single_prompt_folder(\n",
    "    \"flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e7cbc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model: claude_3.5_haiku\n",
      "============================================================\n",
      "ERROR: HTTP 500 - {\"error\": \"Bedrock error: An error occurred (ValidationException) when calling the InvokeModel operation: 'claude-3-5-haiku-20241022' does not support image input.\"}\n",
      "\n",
      "============================================================\n",
      "Model: claude_4_opus\n",
      "============================================================\n",
      "ERROR: HTTP 504 - {\"message\": \"Endpoint request timed out\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Check error from failed models\n",
    "failed_models = ['claude_3.5_haiku', 'claude_4_opus']\n",
    "\n",
    "for model in failed_models:\n",
    "    json_path = Path(f\"flux_experiments/run_20251116_013857/tshirt_design/prompt_0_base/llm_analysis/{model}_analysis.json\")\n",
    "    if json_path.exists():\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Model: {model}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(data['analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfc016bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "\n",
      "==================================================\n",
      "HACKATHON BUDGET USAGE\n",
      "==================================================\n",
      "Budget Limit:        $50.00\n",
      "LLM Cost:            $4.28\n",
      "GPU Cost:            $0.00\n",
      "Total Cost:          $4.28\n",
      "Remaining Budget:    $45.72\n",
      "Budget Used:         8.6%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_ENDPOINT = \"https://ctwa92wg1b.execute-api.us-east-1.amazonaws.com/prod/invoke\"\n",
    "TEAM_ID = \"team_the_great_hack_2025_022\"\n",
    "API_TOKEN = \"znqXT5zCmCynAx-kyx_hldrxvSeyaWvxzx55vB5mfNg\"\n",
    "\n",
    "# Try with api_token in the body as well\n",
    "response = requests.post(\n",
    "    API_ENDPOINT,\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"X-Team-ID\": TEAM_ID,\n",
    "        \"X-API-Token\": API_TOKEN\n",
    "    },\n",
    "    json={\n",
    "        \"team_id\": TEAM_ID,\n",
    "        \"api_token\": API_TOKEN,  # Add this to body\n",
    "        \"model\": \"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hi\"}],\n",
    "        \"max_tokens\": 10\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "result = response.json()\n",
    "\n",
    "if \"metadata\" in result and \"remaining_quota\" in result[\"metadata\"]:\n",
    "    quota = result[\"metadata\"][\"remaining_quota\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"HACKATHON BUDGET USAGE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Budget Limit:        ${quota['budget_limit']:.2f}\")\n",
    "    print(f\"LLM Cost:            ${quota['llm_cost']:.2f}\")\n",
    "    print(f\"GPU Cost:            ${quota['gpu_cost']:.2f}\")\n",
    "    print(f\"Total Cost:          ${quota['total_cost']:.2f}\")\n",
    "    print(f\"Remaining Budget:    ${quota['remaining_budget']:.2f}\")\n",
    "    print(f\"Budget Used:         {quota['budget_usage_percent']:.1f}%\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"\\nFull Response:\")\n",
    "    print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a56894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨\n",
      "AWS BEDROCK API DIAGNOSTIC SUITE\n",
      "üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨üî¨\n",
      "\n",
      "======================================================================\n",
      "TEST 1: Simple Text Request (No Images)\n",
      "======================================================================\n",
      "\n",
      "üì§ Sending request to API...\n",
      "   Endpoint: https://ctwa92wg1b.execute-api.us-east-1.amazonaws.com/prod/invoke\n",
      "   Model: Claude Haiku (fastest)\n",
      "\n",
      "üìä Response Status: 200\n",
      "‚è±Ô∏è  Response Time: 0.36s\n",
      "\n",
      "‚úÖ SUCCESS!\n",
      "\n",
      "üìÑ Full Response:\n",
      "{\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"text\": \"Hello, API connection working!\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 21,\n",
      "    \"output_tokens\": 9,\n",
      "    \"total_tokens\": 30\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"team_id\": \"team_the_great_hack_2025_022\",\n",
      "    \"model\": \"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "    \"cost_usd\": 1.7e-05,\n",
      "    \"latency_ms\": 254.89,\n",
      "    \"remaining_quota\": {\n",
      "      \"requests_today\": 1,\n",
      "      \"tokens_today\": 30,\n",
      "      \"llm_cost\": 2.1521115,\n",
      "      \"gpu_cost\": 0.0,\n",
      "      \"total_cost\": 2.1521115,\n",
      "      \"budget_limit\": 50.0,\n",
      "      \"remaining_budget\": 47.847888499999996,\n",
      "      \"budget_usage_percent\": 4.304223\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "üí¨ LLM Response: Hello, API connection working!\n",
      "\n",
      "======================================================================\n",
      "TEST 2: Testing Multiple Models\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Testing: Claude Haiku\n",
      "   Model ID: us.anthropic.claude-3-haiku-20240307-v1:0\n",
      "   ‚úÖ Success: OK\n",
      "\n",
      "ü§ñ Testing: Nova Lite\n",
      "   Model ID: us.amazon.nova-lite-v1:0\n",
      "   ‚ùå Failed: 500\n",
      "      {\"error\": \"Bedrock error: An error occurred (ValidationException) when calling the InvokeModel operation: Malformed input request: #: extraneous key [temperature] is not permitted, please reformat you\n",
      "\n",
      "ü§ñ Testing: Llama 11B\n",
      "   Model ID: us.meta.llama3-2-11b-instruct-v1:0\n",
      "   ‚úÖ Success: }\n",
      "\n",
      "    # Define the response\n",
      "    response = {'text\n",
      "\n",
      "======================================================================\n",
      "Model Test Summary:\n",
      "======================================================================\n",
      "  Claude Haiku         ‚úÖ Working\n",
      "  Nova Lite            ‚ùå Status 500\n",
      "  Llama 11B            ‚úÖ Working\n",
      "\n",
      "======================================================================\n",
      "TEST 3: Image Upload Test\n",
      "======================================================================\n",
      "\n",
      "üì§ Sending 1x1 pixel test image...\n",
      "üìä Status: 200\n",
      "‚úÖ Image request successful!\n",
      "\n",
      "üìÑ Response:\n",
      "{\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"text\": \"Serene.\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 20,\n",
      "    \"output_tokens\": 7,\n",
      "    \"total_tokens\": 27\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"team_id\": \"team_the_great_hack_2025_022\",\n",
      "    \"model\": \"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "    \"cost_usd\": 1.4e-05,\n",
      "    \"latency_ms\": 409.04,\n",
      "    \"remaining_quota\": {\n",
      "      \"requests_today\": 4,\n",
      "      \"tokens_today\": 146,\n",
      "      \"llm_cost\": 2.1521452,\n",
      "      \"gpu_cost\": 0.0,\n",
      "      \"total_cost\": 2.1521452,\n",
      "      \"budget_limit\": 50.0,\n",
      "      \"remaining_budget\": 47.8478548,\n",
      "      \"budget_usage_percent\": 4.3042904\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "TEST 4: Response Format Analysis\n",
      "======================================================================\n",
      "\n",
      "Status Code: 200\n",
      "Headers: {'Date': 'Sun, 16 Nov 2025 06:52:19 GMT', 'Content-Type': 'application/json', 'Content-Length': '494', 'Connection': 'keep-alive', 'x-amzn-RequestId': 'bd154b33-4638-4508-ad05-217d607309ab', 'Access-Control-Allow-Origin': '*', 'x-amz-apigw-id': 'UH8phEvHoAMERuQ=', 'X-Amzn-Trace-Id': 'Root=1-691974a2-66d9ba3a1a4836953cf268be;Parent=5c4006afda002736;Sampled=0;Lineage=1:d6c64a30:0'}\n",
      "\n",
      "üìä Response Structure:\n",
      "   Type: <class 'dict'>\n",
      "   Keys: ['content', 'usage', 'metadata']\n",
      "\n",
      "üìÑ Full JSON:\n",
      "{\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"text\": \"4\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 14,\n",
      "    \"output_tokens\": 5,\n",
      "    \"total_tokens\": 19\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"team_id\": \"team_the_great_hack_2025_022\",\n",
      "    \"model\": \"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "    \"cost_usd\": 1e-05,\n",
      "    \"latency_ms\": 539.97,\n",
      "    \"remaining_quota\": {\n",
      "      \"requests_today\": 5,\n",
      "      \"tokens_today\": 165,\n",
      "      \"llm_cost\": 2.15215495,\n",
      "      \"gpu_cost\": 0.0,\n",
      "      \"total_cost\": 2.15215495,\n",
      "      \"budget_limit\": 50.0,\n",
      "      \"remaining_budget\": 47.847845050000004,\n",
      "      \"budget_usage_percent\": 4.3043099\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "üîç Extraction Attempts:\n",
      "   ‚úÖ Has 'content' key\n",
      "   ‚úÖ Content has items: 1\n",
      "   ‚úÖ First item has 'text'\n",
      "   üìù Text: 4\n",
      "\n",
      "======================================================================\n",
      "DIAGNOSTIC SUMMARY\n",
      "======================================================================\n",
      "  Test 1 (Simple Text):   ‚úÖ PASS\n",
      "  Test 2 (Multi-Model):   ‚úÖ PASS\n",
      "  Test 3 (Image Upload):  ‚úÖ PASS\n",
      "  Test 4 (Format Check):  ‚úÖ PASS\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AWS Bedrock API Connection Tester\n",
    "Tests API connectivity and authentication with different models\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "API_ENDPOINT = \"https://ctwa92wg1b.execute-api.us-east-1.amazonaws.com/prod/invoke\"\n",
    "TEAM_ID = \"team_the_great_hack_2025_022\"\n",
    "API_TOKEN = \"znqXT5zCmCynAx-kyx_hldrxvSeyaWvxzx55vB5mfNg\"\n",
    "\n",
    "# ===== TEST 1: Simple Text-Only Request =====\n",
    "def test_simple_text_request():\n",
    "    \"\"\"Test basic API connectivity with text-only prompt\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 1: Simple Text Request (No Images)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-api-key\": API_TOKEN\n",
    "    }\n",
    "    \n",
    "    # FIXED: Use snake_case field names\n",
    "    payload = {\n",
    "        \"team_id\": TEAM_ID,  # Changed from teamId\n",
    "        \"api_token\": API_TOKEN,  # Added missing field\n",
    "        \"model\": \"us.anthropic.claude-3-haiku-20240307-v1:0\",  # Changed from modelId\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Say 'Hello, API connection working!' in exactly those words.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüì§ Sending request to API...\")\n",
    "    print(f\"   Endpoint: {API_ENDPOINT}\")\n",
    "    print(f\"   Model: Claude Haiku (fastest)\")\n",
    "    \n",
    "    try:\n",
    "        start = time.time()\n",
    "        response = requests.post(API_ENDPOINT, headers=headers, json=payload, timeout=30)\n",
    "        duration = time.time() - start\n",
    "        \n",
    "        print(f\"\\nüìä Response Status: {response.status_code}\")\n",
    "        print(f\"‚è±Ô∏è  Response Time: {duration:.2f}s\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"\\n‚úÖ SUCCESS!\")\n",
    "            print(f\"\\nüìÑ Full Response:\")\n",
    "            print(json.dumps(result, indent=2))\n",
    "            \n",
    "            # Extract text if available\n",
    "            if \"content\" in result and len(result[\"content\"]) > 0:\n",
    "                text = result[\"content\"][0].get(\"text\", \"No text found\")\n",
    "                print(f\"\\nüí¨ LLM Response: {text}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(f\"\\n‚ùå FAILED!\")\n",
    "            print(f\"\\nüìÑ Error Response:\")\n",
    "            print(response.text)\n",
    "            return False\n",
    "    \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"\\n‚ùå TIMEOUT (>30s)\")\n",
    "        return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {type(e).__name__}\")\n",
    "        print(f\"   Details: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# ===== TEST 2: Different Models =====\n",
    "def test_multiple_models():\n",
    "    \"\"\"Test different models to see which ones work\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST 2: Testing Multiple Models\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    test_models = {\n",
    "        \"Claude Haiku\": \"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "        \"Nova Lite\": \"us.amazon.nova-lite-v1:0\",\n",
    "        \"Llama 11B\": \"us.meta.llama3-2-11b-instruct-v1:0\",\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-api-key\": API_TOKEN\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model_id in test_models.items():\n",
    "        print(f\"\\nü§ñ Testing: {model_name}\")\n",
    "        print(f\"   Model ID: {model_id}\")\n",
    "        \n",
    "        # FIXED: Use snake_case field names\n",
    "        payload = {\n",
    "            \"team_id\": TEAM_ID,\n",
    "            \"api_token\": API_TOKEN,\n",
    "            \"model\": model_id,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": \"Respond with just 'OK'\"}]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 50,\n",
    "            \"temperature\": 0.0\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(API_ENDPOINT, headers=headers, json=payload, timeout=20)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                if \"content\" in result:\n",
    "                    text = result[\"content\"][0].get(\"text\", \"\")\n",
    "                    print(f\"   ‚úÖ Success: {text[:50]}\")\n",
    "                    results[model_name] = \"‚úÖ Working\"\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è  Unexpected response format\")\n",
    "                    results[model_name] = \"‚ö†Ô∏è Unexpected format\"\n",
    "            else:\n",
    "                print(f\"   ‚ùå Failed: {response.status_code}\")\n",
    "                print(f\"      {response.text[:200]}\")\n",
    "                results[model_name] = f\"‚ùå Status {response.status_code}\"\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {str(e)[:100]}\")\n",
    "            results[model_name] = f\"‚ùå {type(e).__name__}\"\n",
    "        \n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Model Test Summary:\")\n",
    "    print(\"=\"*70)\n",
    "    for model, status in results.items():\n",
    "        print(f\"  {model:20s} {status}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===== TEST 3: Image Upload Test =====\n",
    "def test_image_request():\n",
    "    \"\"\"Test API with a small test image\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST 3: Image Upload Test\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create a tiny 1x1 pixel PNG in base64\n",
    "    tiny_png_base64 = \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-api-key\": API_TOKEN\n",
    "    }\n",
    "    \n",
    "    # FIXED: Use snake_case field names\n",
    "    payload = {\n",
    "        \"team_id\": TEAM_ID,\n",
    "        \"api_token\": API_TOKEN,\n",
    "        \"model\": \"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",\n",
    "                            \"data\": tiny_png_base64\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Describe this image in one word.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 50,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüì§ Sending 1x1 pixel test image...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_ENDPOINT, headers=headers, json=payload, timeout=30)\n",
    "        \n",
    "        print(f\"üìä Status: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"‚úÖ Image request successful!\")\n",
    "            print(f\"\\nüìÑ Response:\")\n",
    "            print(json.dumps(result, indent=2))\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Failed!\")\n",
    "            print(f\"\\nüìÑ Error:\")\n",
    "            print(response.text)\n",
    "            return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# ===== TEST 4: Check Response Format =====\n",
    "def test_response_format():\n",
    "    \"\"\"Check the exact response structure from API\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST 4: Response Format Analysis\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-api-key\": API_TOKEN\n",
    "    }\n",
    "    \n",
    "    # FIXED: Use snake_case field names\n",
    "    payload = {\n",
    "        \"team_id\": TEAM_ID,\n",
    "        \"api_token\": API_TOKEN,\n",
    "        \"model\": \"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"What is 2+2?\"}]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 50\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_ENDPOINT, headers=headers, json=payload, timeout=20)\n",
    "        \n",
    "        print(f\"\\nStatus Code: {response.status_code}\")\n",
    "        print(f\"Headers: {dict(response.headers)}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            print(f\"\\nüìä Response Structure:\")\n",
    "            print(f\"   Type: {type(result)}\")\n",
    "            print(f\"   Keys: {list(result.keys())}\")\n",
    "            \n",
    "            print(f\"\\nüìÑ Full JSON:\")\n",
    "            print(json.dumps(result, indent=2))\n",
    "            \n",
    "            # Try different extraction methods\n",
    "            print(f\"\\nüîç Extraction Attempts:\")\n",
    "            \n",
    "            if \"content\" in result:\n",
    "                print(f\"   ‚úÖ Has 'content' key\")\n",
    "                if len(result[\"content\"]) > 0:\n",
    "                    print(f\"   ‚úÖ Content has items: {len(result['content'])}\")\n",
    "                    if \"text\" in result[\"content\"][0]:\n",
    "                        print(f\"   ‚úÖ First item has 'text'\")\n",
    "                        print(f\"   üìù Text: {result['content'][0]['text']}\")\n",
    "            \n",
    "            if \"completion\" in result:\n",
    "                print(f\"   ‚úÖ Has 'completion' key: {result['completion']}\")\n",
    "            \n",
    "            if \"message\" in result:\n",
    "                print(f\"   ‚úÖ Has 'message' key: {result['message']}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Error Response:\")\n",
    "            print(response.text)\n",
    "            return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Exception: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# ===== RUN ALL TESTS =====\n",
    "def run_all_tests():\n",
    "    \"\"\"Run complete diagnostic suite\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"üî¨\"*35)\n",
    "    print(\"AWS BEDROCK API DIAGNOSTIC SUITE\")\n",
    "    print(\"üî¨\"*35 + \"\\n\")\n",
    "    \n",
    "    # Run tests\n",
    "    test1 = test_simple_text_request()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    test2 = test_multiple_models()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    test3 = test_image_request()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    test4 = test_response_format()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DIAGNOSTIC SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"  Test 1 (Simple Text):   {'‚úÖ PASS' if test1 else '‚ùå FAIL'}\")\n",
    "    print(f\"  Test 2 (Multi-Model):   {'‚úÖ PASS' if any('‚úÖ' in v for v in test2.values()) else '‚ùå FAIL'}\")\n",
    "    print(f\"  Test 3 (Image Upload):  {'‚úÖ PASS' if test3 else '‚ùå FAIL'}\")\n",
    "    print(f\"  Test 4 (Format Check):  {'‚úÖ PASS' if test4 else '‚ùå FAIL'}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if not test1:\n",
    "        print(\"\\n‚ö†Ô∏è  DIAGNOSIS: Basic API connection failing\")\n",
    "        print(\"   Check:\")\n",
    "        print(\"   1. API endpoint URL is correct\")\n",
    "        print(\"   2. API token is valid\")\n",
    "        print(\"   3. Team ID is correct\")\n",
    "        print(\"   4. Network/firewall allows connection\")\n",
    "    \n",
    "    elif test1 and not test3:\n",
    "        print(\"\\n‚ö†Ô∏è  DIAGNOSIS: Text works, images fail\")\n",
    "        print(\"   Check:\")\n",
    "        print(\"   1. Image encoding (base64 format)\")\n",
    "        print(\"   2. Model supports vision (Claude 3+, Nova, Pixtral)\")\n",
    "        print(\"   3. Image size limits\")\n",
    "\n",
    "# ===== EXECUTE =====\n",
    "run_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5770db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
