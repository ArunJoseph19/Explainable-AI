{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8809f362",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'valyu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12425/3851804964.py\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# ===== IMPORT AGENT AND FLUX PIPELINE COMPONENTS =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Assumes interact_agent.py is in the same directory or importable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minteract_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPromptSchemaValidator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# FLUX pipeline imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/interact_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmarshmallow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mValyuSearchTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreact_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholistic_ai_bedrock\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHolisticAIBedrockChat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_chat_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemorySaver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mretrievers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mValyuRetriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValyuContentsRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mValyuSearchTool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValyuContentsTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = [\n",
      "\u001b[0;32m~/SageMaker/core/retrievers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrievers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvalyu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mValyu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'valyu'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gradio UI for Image Generation with FLUX.1-Kontext Analysis\n",
    "Combines interact_agent for prompt generation and FLUX analysis pipeline\n",
    "\"\"\"\n",
    "\n",
    "import gradio as gr\n",
    "import json\n",
    "import torch\n",
    "import base64\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# ===== IMPORT AGENT AND FLUX PIPELINE COMPONENTS =====\n",
    "# Assumes interact_agent.py is in the same directory or importable\n",
    "from interact_agent import agent, config, Context, PromptSchemaValidator\n",
    "\n",
    "# FLUX pipeline imports\n",
    "from diffusers import FluxKontextPipeline\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "OUTPUT_ROOT = \"gradio_flux_experiments\"\n",
    "NUM_INFERENCE_STEPS = 28\n",
    "GUIDANCE_SCALE = 3.5\n",
    "MAX_RESOLUTION = 768\n",
    "\n",
    "# ===== LOAD FLUX MODEL (GLOBAL - LOAD ONCE) =====\n",
    "print(\"üîÑ Loading FLUX.1-Kontext-dev model...\")\n",
    "pipe = FluxKontextPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-Kontext-dev\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "pipe.enable_sequential_cpu_offload()\n",
    "pipe.enable_attention_slicing(1)\n",
    "pipe.enable_vae_slicing()\n",
    "print(\"‚úÖ FLUX Model loaded!\\n\")\n",
    "\n",
    "# ===== HELPER FUNCTIONS FROM YOUR CODE =====\n",
    "snapshot_info = []\n",
    "output_dir = None\n",
    "\n",
    "def unpack_flux_latents(latents):\n",
    "    \"\"\"Unpack FLUX latents from [B, seq_len, hidden_dim] to [B, C, H, W]\"\"\"\n",
    "    batch_size = latents.shape[0]\n",
    "    seq_len = latents.shape[1]\n",
    "    hidden_dim = latents.shape[2]\n",
    "    \n",
    "    patch_size = int(seq_len ** 0.5)\n",
    "    latent_channels = 16\n",
    "    \n",
    "    latents = latents.reshape(batch_size, patch_size, patch_size, hidden_dim)\n",
    "    latents = latents.reshape(\n",
    "        batch_size, patch_size, patch_size, latent_channels, \n",
    "        hidden_dim // latent_channels\n",
    "    )\n",
    "    latents = latents[..., 0]\n",
    "    latents = latents.permute(0, 3, 1, 2).contiguous()\n",
    "    \n",
    "    return latents\n",
    "\n",
    "def decode_callback(pipe_obj, step_index, timestep, callback_kwargs):\n",
    "    \"\"\"Decode and save intermediate latents\"\"\"\n",
    "    global output_dir, snapshot_info\n",
    "    \n",
    "    if step_index % 7 != 0 and step_index != 0:\n",
    "        return callback_kwargs\n",
    "    \n",
    "    try:\n",
    "        latents = callback_kwargs[\"latents\"]\n",
    "        snapshot_dir = Path(output_dir) / \"snapshots\"\n",
    "        snapshot_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        unpacked_latents = unpack_flux_latents(latents)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            decoded = pipe_obj.vae.decode(\n",
    "                unpacked_latents / pipe_obj.vae.config.scaling_factor,\n",
    "                return_dict=False\n",
    "            )\n",
    "            \n",
    "            if isinstance(decoded, tuple):\n",
    "                image_tensor = decoded[0]\n",
    "            else:\n",
    "                image_tensor = decoded\n",
    "            \n",
    "            image = (image_tensor / 2 + 0.5).clamp(0, 1)\n",
    "            image = image.cpu().permute(0, 2, 3, 1).float().numpy()[0]\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "            \n",
    "            filepath = snapshot_dir / f\"step_{step_index:03d}_t{timestep:.1f}.png\"\n",
    "            Image.fromarray(image).save(filepath)\n",
    "            snapshot_info.append((step_index, timestep))\n",
    "            \n",
    "            del unpacked_latents, image_tensor, image, decoded\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Failed at step {step_index}: {e}\")\n",
    "    \n",
    "    return callback_kwargs\n",
    "\n",
    "def create_evolution_grid(output_dir):\n",
    "    \"\"\"Create diffusion process evolution grid\"\"\"\n",
    "    snapshot_dir = Path(output_dir) / \"snapshots\"\n",
    "    snapshot_files = sorted(snapshot_dir.glob(\"step_*.png\"))\n",
    "    \n",
    "    if len(snapshot_files) == 0:\n",
    "        return None\n",
    "    \n",
    "    images = [Image.open(f) for f in snapshot_files]\n",
    "    n = len(images)\n",
    "    \n",
    "    cols = min(3, n)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 6*rows))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, (img, file) in enumerate(zip(images, snapshot_files)):\n",
    "        axes[i].imshow(img)\n",
    "        step_info = file.stem.replace(\"step_\", \"Step \").replace(\"_t\", \" | t=\")\n",
    "        axes[i].set_title(step_info, fontsize=12)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    for i in range(n, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = Path(output_dir) / \"evolution_grid.png\"\n",
    "    plt.savefig(save_path, dpi=120, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return str(save_path)\n",
    "\n",
    "# ===== MAIN WORKFLOW FUNCTION =====\n",
    "def generate_image_with_analysis(user_prompt, input_image, num_steps, cfg_scale):\n",
    "    \"\"\"\n",
    "    Complete workflow:\n",
    "    1. Use interact_agent to generate structured prompt\n",
    "    2. Generate image with FLUX\n",
    "    3. Create analysis visualizations\n",
    "    \"\"\"\n",
    "    global output_dir, snapshot_info\n",
    "    \n",
    "    try:\n",
    "        # ===== STEP 1: GENERATE STRUCTURED PROMPT WITH AGENT =====\n",
    "        print(\"üìù Generating structured prompt with interact_agent...\")\n",
    "        \n",
    "        # Convert uploaded image to data URI\n",
    "        if input_image is not None:\n",
    "            mime_type, _ = mimetypes.guess_type(input_image.name)\n",
    "            if mime_type is None:\n",
    "                mime_type = \"image/png\"\n",
    "            \n",
    "            with open(input_image.name, \"rb\") as img_file:\n",
    "                base64_data = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "            \n",
    "            data_uri = f\"data:{mime_type};base64,{base64_data}\"\n",
    "            \n",
    "            # Create message with image\n",
    "            message = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": user_prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}}\n",
    "                ]\n",
    "            }\n",
    "        else:\n",
    "            # Text-only prompt\n",
    "            message = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        \n",
    "        # Invoke agent\n",
    "        response = agent.invoke(\n",
    "            {\"messages\": message},\n",
    "            config=config,\n",
    "            context=Context(user_id=\"gradio_user\")\n",
    "        )\n",
    "        \n",
    "        # Parse agent response\n",
    "        json_string_cleaned = response['messages'][1].content.strip().removeprefix(\"``````\")\n",
    "        \n",
    "        # Validate structured prompt\n",
    "        validator = PromptSchemaValidator(strict_mode=False)\n",
    "        is_valid, errors, warnings = validator.validate(json_string_cleaned)\n",
    "        \n",
    "        if not is_valid:\n",
    "            return None, f\"‚ùå Prompt validation failed:\\n\" + \"\\n\".join(errors), None, None\n",
    "        \n",
    "        structured_data = json.loads(json_string_cleaned)\n",
    "        \n",
    "        # Extract the actual prompt for FLUX (flatten the structure)\n",
    "        flux_prompt = user_prompt  # Use original prompt for simplicity\n",
    "        \n",
    "        # ===== STEP 2: GENERATE IMAGE WITH FLUX =====\n",
    "        print(\"üé® Generating image with FLUX.1-Kontext...\")\n",
    "        \n",
    "        # Create output directory\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_dir = Path(OUTPUT_ROOT) / f\"generation_{timestamp}\"\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        snapshot_info = []\n",
    "        \n",
    "        # Save structured prompt\n",
    "        with open(output_dir / \"structured_prompt.json\", \"w\") as f:\n",
    "            json.dump(structured_data, f, indent=2)\n",
    "        \n",
    "        # Load and resize input image\n",
    "        if input_image is not None:\n",
    "            input_pil = Image.open(input_image.name).convert(\"RGB\")\n",
    "            if max(input_pil.size) > MAX_RESOLUTION:\n",
    "                ratio = MAX_RESOLUTION / max(input_pil.size)\n",
    "                new_size = tuple(int(dim * ratio // 16 * 16) for dim in input_pil.size)\n",
    "                input_pil = input_pil.resize(new_size, Image.Resampling.LANCZOS)\n",
    "            \n",
    "            input_pil.save(output_dir / \"input_image.png\")\n",
    "        else:\n",
    "            return None, \"‚ö†Ô∏è Input image required for FLUX.1-Kontext\", None, None\n",
    "        \n",
    "        # Generate with FLUX\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        generator = torch.Generator(\"cuda\").manual_seed(42)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            result = pipe(\n",
    "                prompt=flux_prompt,\n",
    "                image=input_pil,\n",
    "                num_inference_steps=int(num_steps),\n",
    "                guidance_scale=float(cfg_scale),\n",
    "                generator=generator,\n",
    "                callback_on_step_end=decode_callback,\n",
    "                callback_on_step_end_tensor_inputs=[\"latents\"]\n",
    "            )\n",
    "        \n",
    "        final_image = result.images[0]\n",
    "        final_image.save(output_dir / \"final_output.png\")\n",
    "        \n",
    "        # ===== STEP 3: CREATE VISUALIZATIONS =====\n",
    "        print(\"üìä Creating analysis visualizations...\")\n",
    "        evolution_grid_path = create_evolution_grid(output_dir)\n",
    "        \n",
    "        # Prepare outputs\n",
    "        status_message = f\"‚úÖ Generation complete!\\nüìÅ Output saved to: {output_dir}\"\n",
    "        \n",
    "        # Format structured prompt for display\n",
    "        prompt_display = json.dumps(structured_data, indent=2)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return (\n",
    "            str(output_dir / \"final_output.png\"),  # Final image\n",
    "            status_message,  # Status\n",
    "            prompt_display,  # Structured prompt JSON\n",
    "            evolution_grid_path  # Evolution grid\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_msg = f\"‚ùå Error: {str(e)}\\n\\n{traceback.format_exc()}\"\n",
    "        return None, error_msg, None, None\n",
    "\n",
    "# ===== GRADIO INTERFACE =====\n",
    "with gr.Blocks(title=\"FLUX.1-Kontext + Agent Analysis\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé® Image Generation with FLUX.1-Kontext + Prompt Agent\n",
    "    \n",
    "    This interface combines:\n",
    "    1. **Interact Agent**: Generates structured, safe prompts\n",
    "    2. **FLUX.1-Kontext**: Image generation with analysis\n",
    "    3. **Automatic Visualization**: Evolution grids and analysis outputs\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            # INPUTS\n",
    "            gr.Markdown(\"### üì• Input\")\n",
    "            \n",
    "            user_prompt_input = gr.Textbox(\n",
    "                label=\"Prompt\",\n",
    "                placeholder=\"E.g., 'transform logo into festive holiday mug design'\",\n",
    "                lines=3\n",
    "            )\n",
    "            \n",
    "            input_image_upload = gr.File(\n",
    "                label=\"Input Image (Required)\",\n",
    "                file_types=[\"image\"]\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                num_steps_slider = gr.Slider(\n",
    "                    minimum=10,\n",
    "                    maximum=50,\n",
    "                    value=NUM_INFERENCE_STEPS,\n",
    "                    step=1,\n",
    "                    label=\"Inference Steps\"\n",
    "                )\n",
    "                \n",
    "                cfg_scale_slider = gr.Slider(\n",
    "                    minimum=1.0,\n",
    "                    maximum=10.0,\n",
    "                    value=GUIDANCE_SCALE,\n",
    "                    step=0.5,\n",
    "                    label=\"CFG Scale\"\n",
    "                )\n",
    "            \n",
    "            generate_btn = gr.Button(\"üöÄ Generate\", variant=\"primary\", size=\"lg\")\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            # OUTPUTS\n",
    "            gr.Markdown(\"### üì§ Output\")\n",
    "            \n",
    "            status_output = gr.Textbox(label=\"Status\", lines=3)\n",
    "            \n",
    "            final_image_output = gr.Image(label=\"Generated Image\", type=\"filepath\")\n",
    "            \n",
    "            with gr.Accordion(\"üìã Structured Prompt (JSON)\", open=False):\n",
    "                structured_prompt_output = gr.Code(\n",
    "                    label=\"Generated Structured Prompt\",\n",
    "                    language=\"json\"\n",
    "                )\n",
    "            \n",
    "            with gr.Accordion(\"üìä Evolution Grid\", open=False):\n",
    "                evolution_grid_output = gr.Image(label=\"Diffusion Process Evolution\")\n",
    "    \n",
    "    # ===== EVENT HANDLER =====\n",
    "    generate_btn.click(\n",
    "        fn=generate_image_with_analysis,\n",
    "        inputs=[\n",
    "            user_prompt_input,\n",
    "            input_image_upload,\n",
    "            num_steps_slider,\n",
    "            cfg_scale_slider\n",
    "        ],\n",
    "        outputs=[\n",
    "            final_image_output,\n",
    "            status_output,\n",
    "            structured_prompt_output,\n",
    "            evolution_grid_output\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # ===== EXAMPLES =====\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"transform logo into festive holiday mug design with snowflakes\", None, 28, 3.5],\n",
    "            [\"adapt logo for holiday t-shirt print with seasonal elements\", None, 28, 3.5],\n",
    "            [\"convert logo to christmas gift bag design with wrapping elements\", None, 28, 3.5],\n",
    "        ],\n",
    "        inputs=[user_prompt_input, input_image_upload, num_steps_slider, cfg_scale_slider]\n",
    "    )\n",
    "\n",
    "# ===== LAUNCH =====\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(\n",
    "        share=False,  # Set to True to create public link\n",
    "        server_name=\"0.0.0.0\",  # Allow external access\n",
    "        server_port=7862\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
