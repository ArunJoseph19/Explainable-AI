{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac4ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "* Running on public URL: https://5bfdf411afa5105c7e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5bfdf411afa5105c7e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "FLUX.1-Kontext Explainability Web Dashboard\n",
    "Standalone web interface with Gradio\n",
    "\"\"\"\n",
    "\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "EXPERIMENT_ROOT = Path(\"flux_experiments/run_20251116_013857\")\n",
    "INPUT_IMAGE = \"holistic.png\"\n",
    "\n",
    "# AWS Bedrock Configuration\n",
    "API_ENDPOINT = \"https://ctwa92wg1b.execute-api.us-east-1.amazonaws.com/prod/invoke\"\n",
    "TEAM_ID = \"team_the_great_hack_2025_022\"\n",
    "API_TOKEN = \"znqXT5zCmCynAx-kyx_hldrxvSeyaWvxzx55vB5mfNg\"\n",
    "\n",
    "LLMS_AVAILABLE = {\n",
    "    \"Claude 3.5 Sonnet (Recommended)\": \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "    \"Claude 4.5 Sonnet (Latest)\": \"us.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
    "    \"Claude 4 Opus (Powerful)\": \"us.anthropic.claude-opus-4-20250514-v1:0\",\n",
    "    \"Claude 3 Opus\": \"us.anthropic.claude-3-opus-20240229-v1:0\",\n",
    "}\n",
    "\n",
    "# ===== UTILITY FUNCTIONS =====\n",
    "\n",
    "def resize_image_for_api(image_path, max_dimension=1200, quality=80):\n",
    "    \"\"\"Resize and encode image for Bedrock API\"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        if img.mode not in ('RGB', 'L'):\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        width, height = img.size\n",
    "        if max(width, height) > max_dimension:\n",
    "            if width > height:\n",
    "                new_width = max_dimension\n",
    "                new_height = int(height * (max_dimension / width))\n",
    "            else:\n",
    "                new_height = max_dimension\n",
    "                new_width = int(width * (max_dimension / height))\n",
    "            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format='JPEG', quality=quality, optimize=True)\n",
    "        buffer.seek(0)\n",
    "        \n",
    "        img_b64 = base64.b64encode(buffer.read()).decode('utf-8')\n",
    "        return img_b64, 'image/jpeg'\n",
    "\n",
    "def call_bedrock_llm(model_id, prompt, images=None):\n",
    "    \"\"\"Call AWS Bedrock API\"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-api-key\": API_TOKEN\n",
    "    }\n",
    "    \n",
    "    content = []\n",
    "    if images:\n",
    "        for img_path in images:\n",
    "            try:\n",
    "                img_b64, media_type = resize_image_for_api(img_path)\n",
    "                content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": media_type,\n",
    "                        \"data\": img_b64\n",
    "                    }\n",
    "                })\n",
    "            except Exception as e:\n",
    "                return f\"ERROR: Failed to encode {img_path}: {str(e)}\"\n",
    "    \n",
    "    content.append({\"type\": \"text\", \"text\": prompt})\n",
    "    \n",
    "    payload = {\n",
    "        \"team_id\": TEAM_ID,\n",
    "        \"api_token\": API_TOKEN,\n",
    "        \"model\": model_id,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": content}],\n",
    "        \"max_tokens\": 2000,\n",
    "        \"temperature\": 0.3\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_ENDPOINT, headers=headers, json=payload, timeout=90)\n",
    "        if response.status_code != 200:\n",
    "            return f\"ERROR: HTTP {response.status_code} - {response.text[:300]}\"\n",
    "        \n",
    "        result = response.json()\n",
    "        if \"content\" in result and len(result[\"content\"]) > 0:\n",
    "            return result[\"content\"][0][\"text\"]\n",
    "        return result.get(\"completion\", \"No response\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {type(e).__name__}: {str(e)}\"\n",
    "\n",
    "def generate_analysis_prompt(prompt_text, scenario_name):\n",
    "    \"\"\"Generate LLM analysis prompt\"\"\"\n",
    "    return f\"\"\"You are an expert in AI image generation and prompt engineering for diffusion models.\n",
    "\n",
    "**Task**: Analyze this logo transformation for {scenario_name} design.\n",
    "\n",
    "**Prompt used**: \"{prompt_text}\"\n",
    "**Model**: FLUX.1-Kontext-dev\n",
    "\n",
    "**Images provided**:\n",
    "1. Input logo (original)\n",
    "2. Generated output (transformed design)\n",
    "3. Word attribution (3 rows: WITH word, WITHOUT word, difference heatmap)\n",
    "4. Evolution grid (diffusion timesteps)\n",
    "\n",
    "**Provide concise analysis**:\n",
    "\n",
    "### 1. Prompt Adherence\n",
    "Did the model follow instructions? What elements match/miss the prompt?\n",
    "\n",
    "### 2. Logo Preservation\n",
    "Is the original logo recognizable? Brand elements preserved?\n",
    "\n",
    "### 3. Design Quality\n",
    "Would this work for merchandise? Print quality concerns?\n",
    "\n",
    "### 4. Word Attribution Insights\n",
    "Which words (from attribution visualization) had the most impact? Which words are redundant or ineffective?\n",
    "\n",
    "### 5. Prompt Improvements\n",
    "Provide 3 specific, actionable changes to improve the output. Reference the word attribution results to explain WHY these changes will help.\n",
    "\n",
    "**Format**: Use clear headings and bullet points. Be specific and actionable.\"\"\"\n",
    "\n",
    "def get_experiment_structure():\n",
    "    \"\"\"Scan experiment folder and return structure\"\"\"\n",
    "    structure = {}\n",
    "    if not EXPERIMENT_ROOT.exists():\n",
    "        return structure\n",
    "    \n",
    "    for scenario_dir in sorted(EXPERIMENT_ROOT.iterdir()):\n",
    "        if scenario_dir.is_dir():\n",
    "            scenario_name = scenario_dir.name\n",
    "            structure[scenario_name] = []\n",
    "            \n",
    "            for prompt_dir in sorted(scenario_dir.iterdir()):\n",
    "                if prompt_dir.is_dir() and prompt_dir.name.startswith(\"prompt_\"):\n",
    "                    metadata_file = prompt_dir / \"metadata.json\"\n",
    "                    if metadata_file.exists():\n",
    "                        with open(metadata_file) as f:\n",
    "                            metadata = json.load(f)\n",
    "                        \n",
    "                        structure[scenario_name].append({\n",
    "                            \"name\": prompt_dir.name,\n",
    "                            \"path\": prompt_dir,\n",
    "                            \"prompt\": metadata.get(\"prompt\", \"N/A\"),\n",
    "                            \"metadata\": metadata\n",
    "                        })\n",
    "    \n",
    "    return structure\n",
    "\n",
    "def calculate_word_impact(prompt_dir):\n",
    "    \"\"\"Calculate impact scores from ablated images\"\"\"\n",
    "    baseline_path = prompt_dir / \"final_output.png\"\n",
    "    if not baseline_path.exists():\n",
    "        return {}\n",
    "    \n",
    "    baseline = np.array(Image.open(baseline_path).convert('RGB')).astype(float)\n",
    "    \n",
    "    ablated_files = list(prompt_dir.glob(\"ablated_without_*.png\"))\n",
    "    impacts = {}\n",
    "    \n",
    "    for ablated_path in ablated_files:\n",
    "        word = ablated_path.stem.replace(\"ablated_without_\", \"\")\n",
    "        ablated = np.array(Image.open(ablated_path).convert('RGB')).astype(float)\n",
    "        \n",
    "        diff = np.linalg.norm(baseline - ablated, axis=2)\n",
    "        impact_score = diff.mean()\n",
    "        \n",
    "        impacts[word] = {\n",
    "            \"score\": impact_score,\n",
    "            \"path\": str(ablated_path)\n",
    "        }\n",
    "    \n",
    "    # Sort by impact score descending\n",
    "    return dict(sorted(impacts.items(), key=lambda x: x[1][\"score\"], reverse=True))\n",
    "\n",
    "# ===== GRADIO FUNCTIONS =====\n",
    "\n",
    "experiment_data = get_experiment_structure()\n",
    "\n",
    "def get_prompts_for_scenario(scenario):\n",
    "    \"\"\"Get prompt options for selected scenario\"\"\"\n",
    "    if not scenario or scenario not in experiment_data:\n",
    "        return gr.Dropdown(choices=[])\n",
    "    \n",
    "    prompts = experiment_data[scenario]\n",
    "    choices = [(f\"{p['name']}: {p['prompt'][:60]}...\", p['name']) for p in prompts]\n",
    "    return gr.Dropdown(choices=choices, value=choices[0][1] if choices else None)\n",
    "\n",
    "def load_visualization(scenario, prompt_name):\n",
    "    \"\"\"Load all visualizations for selected prompt\"\"\"\n",
    "    if not scenario or not prompt_name:\n",
    "        return None, None, None, None, None, \"‚ö†Ô∏è Please select a scenario and prompt\"\n",
    "    \n",
    "    # Find prompt data\n",
    "    prompt_data = None\n",
    "    for p in experiment_data[scenario]:\n",
    "        if p['name'] == prompt_name:\n",
    "            prompt_data = p\n",
    "            break\n",
    "    \n",
    "    if not prompt_data:\n",
    "        return None, None, None, None, None, \"‚ùå Prompt not found\"\n",
    "    \n",
    "    prompt_path = prompt_data['path']\n",
    "    prompt_text = prompt_data['prompt']\n",
    "    \n",
    "    # Load images\n",
    "    input_img = str(prompt_path / \"input_image.png\") if (prompt_path / \"input_image.png\").exists() else None\n",
    "    output_img = str(prompt_path / \"final_output.png\") if (prompt_path / \"final_output.png\").exists() else None\n",
    "    attr_img = str(prompt_path / \"word_attribution_complete.png\") if (prompt_path / \"word_attribution_complete.png\").exists() else None\n",
    "    evolution_img = str(prompt_path / \"evolution_grid.png\") if (prompt_path / \"evolution_grid.png\").exists() else None\n",
    "    \n",
    "    # Get word impacts\n",
    "    impacts = calculate_word_impact(prompt_path)\n",
    "    impact_text = \"### üìä Word Impact Rankings\\n\\n\"\n",
    "    for i, (word, data) in enumerate(impacts.items(), 1):\n",
    "        impact_text += f\"**#{i} \\\"{word}\\\"** - Impact Score: {data['score']:.2f}\\n\\n\"\n",
    "    \n",
    "    if not impacts:\n",
    "        impact_text = \"‚ö†Ô∏è No word impact data available\"\n",
    "    \n",
    "    info_text = f\"\"\"## üìù Current Prompt\n",
    "\n",
    "**{prompt_text}**\n",
    "\n",
    "---\n",
    "\n",
    "{impact_text}\n",
    "\"\"\"\n",
    "    \n",
    "    return input_img, output_img, attr_img, evolution_img, info_text, \"‚úÖ Visualization loaded\"\n",
    "\n",
    "def get_evolution_snapshots(scenario, prompt_name):\n",
    "    \"\"\"Get list of evolution snapshots for timeline\"\"\"\n",
    "    if not scenario or not prompt_name:\n",
    "        return gr.Slider(maximum=0), None\n",
    "    \n",
    "    # Find prompt data\n",
    "    prompt_data = None\n",
    "    for p in experiment_data[scenario]:\n",
    "        if p['name'] == prompt_name:\n",
    "            prompt_data = p\n",
    "            break\n",
    "    \n",
    "    if not prompt_data:\n",
    "        return gr.Slider(maximum=0), None\n",
    "    \n",
    "    snapshot_dir = prompt_data['path'] / \"snapshots\"\n",
    "    if not snapshot_dir.exists():\n",
    "        return gr.Slider(maximum=0), None\n",
    "    \n",
    "    snapshots = sorted(snapshot_dir.glob(\"step_*.png\"))\n",
    "    if not snapshots:\n",
    "        return gr.Slider(maximum=0), None\n",
    "    \n",
    "    return gr.Slider(maximum=len(snapshots)-1, value=0), str(snapshots[0])\n",
    "\n",
    "def show_evolution_step(scenario, prompt_name, step_index):\n",
    "    \"\"\"Show specific evolution step\"\"\"\n",
    "    if not scenario or not prompt_name:\n",
    "        return None\n",
    "    \n",
    "    # Find prompt data\n",
    "    prompt_data = None\n",
    "    for p in experiment_data[scenario]:\n",
    "        if p['name'] == prompt_name:\n",
    "            prompt_data = p\n",
    "            break\n",
    "    \n",
    "    if not prompt_data:\n",
    "        return None\n",
    "    \n",
    "    snapshot_dir = prompt_data['path'] / \"snapshots\"\n",
    "    if not snapshot_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    snapshots = sorted(snapshot_dir.glob(\"step_*.png\"))\n",
    "    if 0 <= step_index < len(snapshots):\n",
    "        return str(snapshots[step_index])\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_ablated_images(scenario, prompt_name):\n",
    "    \"\"\"Get ablated images for display\"\"\"\n",
    "    if not scenario or not prompt_name:\n",
    "        return [None] * 4\n",
    "    \n",
    "    # Find prompt data\n",
    "    prompt_data = None\n",
    "    for p in experiment_data[scenario]:\n",
    "        if p['name'] == prompt_name:\n",
    "            prompt_data = p\n",
    "            break\n",
    "    \n",
    "    if not prompt_data:\n",
    "        return [None] * 4\n",
    "    \n",
    "    impacts = calculate_word_impact(prompt_data['path'])\n",
    "    ablated_imgs = []\n",
    "    \n",
    "    for word, data in list(impacts.items())[:4]:  # Top 4\n",
    "        ablated_imgs.append(str(data['path']))\n",
    "    \n",
    "    # Pad with None if less than 4\n",
    "    while len(ablated_imgs) < 4:\n",
    "        ablated_imgs.append(None)\n",
    "    \n",
    "    return ablated_imgs\n",
    "\n",
    "def analyze_with_llm(scenario, prompt_name, llm_choice, progress=gr.Progress()):\n",
    "    \"\"\"Run LLM analysis\"\"\"\n",
    "    if not scenario or not prompt_name:\n",
    "        return \"‚ö†Ô∏è Please select a scenario and prompt first\"\n",
    "    \n",
    "    progress(0, desc=\"Finding prompt data...\")\n",
    "    \n",
    "    # Find prompt data\n",
    "    prompt_data = None\n",
    "    for p in experiment_data[scenario]:\n",
    "        if p['name'] == prompt_name:\n",
    "            prompt_data = p\n",
    "            break\n",
    "    \n",
    "    if not prompt_data:\n",
    "        return \"‚ùå Prompt not found\"\n",
    "    \n",
    "    prompt_path = prompt_data['path']\n",
    "    prompt_text = prompt_data['prompt']\n",
    "    scenario_name = scenario.replace('_', ' ')\n",
    "    \n",
    "    progress(0.2, desc=\"Collecting images...\")\n",
    "    \n",
    "    # Collect images\n",
    "    images_to_analyze = []\n",
    "    for img_name in [\"input_image.png\", \"final_output.png\", \n",
    "                      \"word_attribution_complete.png\", \"evolution_grid.png\"]:\n",
    "        img_path = prompt_path / img_name\n",
    "        if img_path.exists():\n",
    "            images_to_analyze.append(str(img_path))\n",
    "    \n",
    "    progress(0.4, desc=\"Generating analysis prompt...\")\n",
    "    \n",
    "    # Generate analysis prompt\n",
    "    analysis_prompt = generate_analysis_prompt(prompt_text, scenario_name)\n",
    "    \n",
    "    # Get model ID\n",
    "    model_id = LLMS_AVAILABLE[llm_choice]\n",
    "    \n",
    "    progress(0.5, desc=f\"Calling {llm_choice}... (this may take 30-60s)\")\n",
    "    \n",
    "    # Call LLM\n",
    "    start_time = time.time()\n",
    "    response = call_bedrock_llm(model_id, analysis_prompt, images_to_analyze)\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    progress(0.9, desc=\"Saving results...\")\n",
    "    \n",
    "    if not response.startswith(\"ERROR\"):\n",
    "        # Save analysis\n",
    "        output_dir = prompt_path / \"llm_analysis\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        llm_key = llm_choice.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "        result = {\n",
    "            \"llm\": llm_choice,\n",
    "            \"model_id\": model_id,\n",
    "            \"prompt\": prompt_text,\n",
    "            \"analysis\": response,\n",
    "            \"response_time_seconds\": duration,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "        \n",
    "        with open(output_dir / f\"{llm_key}_analysis.json\", \"w\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        progress(1.0, desc=\"Complete!\")\n",
    "        \n",
    "        return f\"\"\"‚úÖ **Analysis Complete** (took {duration:.1f}s)\n",
    "\n",
    "---\n",
    "\n",
    "{response}\n",
    "\"\"\"\n",
    "    else:\n",
    "        return f\"‚ùå **Analysis Failed**\\n\\n{response}\"\n",
    "\n",
    "# ===== BUILD GRADIO INTERFACE =====\n",
    "\n",
    "with gr.Blocks(title=\"FLUX.1-Kontext Explainability Dashboard\", theme=gr.themes.Soft()) as demo:\n",
    "    \n",
    "    gr.HTML(\"\"\"\n",
    "    <div style='text-align: center; padding: 30px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; margin-bottom: 30px;'>\n",
    "        <h1 style='color: white; margin: 0; font-size: 2.5em;'>üé® FLUX.1-Kontext Explainability Dashboard</h1>\n",
    "        <p style='color: #f0f0f0; margin: 10px 0 0 0; font-size: 1.2em;'>\n",
    "            Interactive Analysis of Diffusion Model Image Generation\n",
    "        </p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"## üéØ Navigation\")\n",
    "            \n",
    "            scenario_dropdown = gr.Dropdown(\n",
    "                choices=list(experiment_data.keys()),\n",
    "                label=\"Select Scenario\",\n",
    "                value=list(experiment_data.keys())[0] if experiment_data else None\n",
    "            )\n",
    "            \n",
    "            prompt_dropdown = gr.Dropdown(\n",
    "                choices=[],\n",
    "                label=\"Select Prompt Variant\"\n",
    "            )\n",
    "            \n",
    "            load_button = gr.Button(\"üìä Load Visualization\", variant=\"primary\", size=\"lg\")\n",
    "            \n",
    "            status_text = gr.Markdown(\"‚ÑπÔ∏è Select a scenario and prompt to begin\")\n",
    "            \n",
    "            gr.Markdown(\"---\")\n",
    "            gr.Markdown(\"## ü§ñ LLM Analysis\")\n",
    "            \n",
    "            llm_dropdown = gr.Dropdown(\n",
    "                choices=list(LLMS_AVAILABLE.keys()),\n",
    "                label=\"Select LLM Model\",\n",
    "                value=\"Claude 3.5 Sonnet (Recommended)\"\n",
    "            )\n",
    "            \n",
    "            analyze_button = gr.Button(\"üîç Analyze with LLM\", variant=\"success\", size=\"lg\")\n",
    "        \n",
    "        with gr.Column(scale=3):\n",
    "            gr.Markdown(\"## üì∏ Input ‚Üí Output Comparison\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                input_image = gr.Image(label=\"üéØ Input Logo\", height=300)\n",
    "                output_image = gr.Image(label=\"‚ú® Generated Output\", height=300)\n",
    "            \n",
    "            info_markdown = gr.Markdown(\"Select a prompt to view details\")\n",
    "            \n",
    "            gr.Markdown(\"## üî¨ Word Attribution Analysis\")\n",
    "            gr.Markdown(\"*Shows impact of individual words: WITH word (top), WITHOUT word (middle), Difference heatmap (bottom)*\")\n",
    "            attribution_image = gr.Image(label=\"Word Attribution Visualization\", height=400)\n",
    "            \n",
    "            gr.Markdown(\"## üñºÔ∏è Ablated Images (Top Impact Words)\")\n",
    "            with gr.Row():\n",
    "                ablated_1 = gr.Image(label=\"Word #1 Removed\", height=200)\n",
    "                ablated_2 = gr.Image(label=\"Word #2 Removed\", height=200)\n",
    "                ablated_3 = gr.Image(label=\"Word #3 Removed\", height=200)\n",
    "                ablated_4 = gr.Image(label=\"Word #4 Removed\", height=200)\n",
    "            \n",
    "            gr.Markdown(\"## ‚è±Ô∏è Diffusion Process Evolution\")\n",
    "            evolution_image = gr.Image(label=\"Evolution Grid\", height=400)\n",
    "            \n",
    "            gr.Markdown(\"## üé¨ Interactive Timeline\")\n",
    "            timeline_slider = gr.Slider(\n",
    "                minimum=0,\n",
    "                maximum=10,\n",
    "                step=1,\n",
    "                value=0,\n",
    "                label=\"Scrub through denoising steps\"\n",
    "            )\n",
    "            timeline_image = gr.Image(label=\"Current Step\", height=350)\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"## üìù LLM Analysis Results\")\n",
    "            analysis_output = gr.Markdown(\"Click 'Analyze with LLM' to generate analysis\")\n",
    "    \n",
    "    # Event handlers\n",
    "    scenario_dropdown.change(\n",
    "        fn=get_prompts_for_scenario,\n",
    "        inputs=[scenario_dropdown],\n",
    "        outputs=[prompt_dropdown]\n",
    "    )\n",
    "    \n",
    "    load_button.click(\n",
    "        fn=load_visualization,\n",
    "        inputs=[scenario_dropdown, prompt_dropdown],\n",
    "        outputs=[input_image, output_image, attribution_image, evolution_image, info_markdown, status_text]\n",
    "    ).then(\n",
    "        fn=get_evolution_snapshots,\n",
    "        inputs=[scenario_dropdown, prompt_dropdown],\n",
    "        outputs=[timeline_slider, timeline_image]\n",
    "    ).then(\n",
    "        fn=get_ablated_images,\n",
    "        inputs=[scenario_dropdown, prompt_dropdown],\n",
    "        outputs=[ablated_1, ablated_2, ablated_3, ablated_4]\n",
    "    )\n",
    "    \n",
    "    timeline_slider.change(\n",
    "        fn=show_evolution_step,\n",
    "        inputs=[scenario_dropdown, prompt_dropdown, timeline_slider],\n",
    "        outputs=[timeline_image]\n",
    "    )\n",
    "    \n",
    "    analyze_button.click(\n",
    "        fn=analyze_with_llm,\n",
    "        inputs=[scenario_dropdown, prompt_dropdown, llm_dropdown],\n",
    "        outputs=[analysis_output]\n",
    "    )\n",
    "\n",
    "# ===== LAUNCH =====\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(\n",
    "        server_name=\"0.0.0.0\",  # Makes it accessible from outside\n",
    "        server_port=7860,\n",
    "        share=True,  # Creates public URL\n",
    "        debug=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
